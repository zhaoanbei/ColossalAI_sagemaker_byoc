{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4317ee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/colo3/diffusion\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac903a09",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-west-2\n",
      "310850127430.dkr.ecr.us-west-2.amazonaws.com/diffusion:latest\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon   1.93MB\n",
      "Step 1/18 : From hpcaitech/colossalai:0.2.5\n",
      " ---> 70d7ca75a2e7\n",
      "Step 2/18 : RUN apt-get install libgl1-mesa-glx  -y\n",
      " ---> Using cache\n",
      " ---> 636431ded217\n",
      "Step 3/18 : ENV LANG=en_US.utf8\n",
      " ---> Using cache\n",
      " ---> 76d3aabae4ad\n",
      "Step 4/18 : ENV LANG=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 8bbef8ed6d2f\n",
      "Step 5/18 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> d95f60724ea8\n",
      "Step 6/18 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 935c489a424c\n",
      "Step 7/18 : ENV PATH=\"/opt/ml:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 0890a94244b8\n",
      "Step 8/18 : WORKDIR /opt/ml\n",
      " ---> Using cache\n",
      " ---> 5e8030f8039c\n",
      "Step 9/18 : RUN wget --no-verbose https://huggingface.co/stabilityai/stable-diffusion-2-base/resolve/main/512-base-ema.ckpt\n",
      " ---> Using cache\n",
      " ---> e240834ac0a4\n",
      "Step 10/18 : COPY . /opt/ml\n",
      " ---> 8f13e4b683d6\n",
      "Step 11/18 : RUN ls /opt/ml\n",
      " ---> Running in 0dfff3dd71e3\n",
      "512-base-ema.ckpt\n",
      "Dockerfile\n",
      "LICENSE\n",
      "README.md\n",
      "build_and_push\n",
      "configs\n",
      "diffusion_byoc.ipynb\n",
      "docker\n",
      "environment.yaml\n",
      "ldm\n",
      "main.py\n",
      "main_1.py\n",
      "requirements.txt\n",
      "requirements.txt.1\n",
      "scripts\n",
      "setup.py\n",
      "test_ci.sh\n",
      "train\n",
      "train_colossalai.sh\n",
      "train_colossalai_teyvat.yaml\n",
      "train_ddp.sh\n",
      "Removing intermediate container 0dfff3dd71e3\n",
      " ---> 89472d479648\n",
      "Step 12/18 : RUN pip install -r requirements.txt.1 && pip install lightning boto3\n",
      " ---> Running in e26b257099f5\n",
      "Obtaining file:///opt/ml (from -r requirements.txt.1 (line 18))\n",
      "Collecting albumentations==1.3.0\n",
      "  Downloading albumentations-1.3.0-py3-none-any.whl (123 kB)\n",
      "Collecting opencv-python==4.6.0.66\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
      "Collecting pudb==2019.2\n",
      "  Downloading pudb-2019.2.tar.gz (59 kB)\n",
      "Collecting prefetch_generator\n",
      "  Downloading prefetch_generator-1.0.3.tar.gz (4.6 kB)\n",
      "Collecting imageio==2.9.0\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "Collecting imageio-ffmpeg==0.4.2\n",
      "  Downloading imageio_ffmpeg-0.4.2-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "Collecting torchmetrics==0.6\n",
      "  Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n",
      "Collecting omegaconf==2.1.1\n",
      "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
      "Collecting test-tube>=0.7.5\n",
      "  Downloading test_tube-0.7.5.tar.gz (21 kB)\n",
      "Collecting streamlit>=0.73.1\n",
      "  Downloading streamlit-1.19.0-py2.py3-none-any.whl (9.6 MB)\n",
      "Collecting einops==0.3.0\n",
      "  Downloading einops-0.3.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting transformers==4.19.2\n",
      "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
      "Collecting webdataset==0.2.5\n",
      "  Downloading webdataset-0.2.5-py3-none-any.whl (46 kB)\n",
      "Collecting open-clip-torch==2.7.0\n",
      "  Downloading open_clip_torch-2.7.0-py3-none-any.whl (1.4 MB)\n",
      "Collecting gradio==3.11\n",
      "  Downloading gradio-3.11.0-py3-none-any.whl (11.6 MB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
      "Requirement already satisfied: colossalai in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt.1 (line 17)) (0.2.0+torch1.12cu11.3)\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.2 MB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.9/site-packages (from albumentations==1.3.0->-r requirements.txt.1 (line 1)) (1.22.3)\n",
      "Collecting scikit-image>=0.16.1\n",
      "  Downloading scikit_image-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.9/site-packages (from albumentations==1.3.0->-r requirements.txt.1 (line 1)) (6.0)\n",
      "Collecting urwid>=1.1.1\n",
      "  Downloading urwid-2.1.2.tar.gz (634 kB)\n",
      "Requirement already satisfied: pygments>=1.0 in /opt/conda/lib/python3.9/site-packages (from pudb==2019.2->-r requirements.txt.1 (line 3)) (2.14.0)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.9/site-packages (from imageio==2.9.0->-r requirements.txt.1 (line 5)) (9.0.1)\n",
      "Requirement already satisfied: torch>=1.3.1 in /opt/conda/lib/python3.9/site-packages (from torchmetrics==0.6->-r requirements.txt.1 (line 7)) (1.12.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from torchmetrics==0.6->-r requirements.txt.1 (line 7)) (23.0)\n",
      "Collecting antlr4-python3-runtime==4.8\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.19.2->-r requirements.txt.1 (line 12)) (4.63.0)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.19.2->-r requirements.txt.1 (line 12)) (3.9.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.19.2->-r requirements.txt.1 (line 12)) (2.27.1)\n",
      "Collecting braceexpand\n",
      "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.9/site-packages (from open-clip-torch==2.7.0->-r requirements.txt.1 (line 14)) (0.13.1)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
      "Collecting python-multipart\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "Collecting markdown-it-py[linkify,plugins]\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "Collecting jinja2\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Collecting pycryptodome\n",
      "  Downloading pycryptodome-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.92.0-py3-none-any.whl (56 kB)\n",
      "Collecting websockets>=10.0\n",
      "  Downloading websockets-10.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "Collecting httpx\n",
      "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
      "Collecting orjson\n",
      "  Downloading orjson-3.8.7-cp39-cp39-manylinux_2_28_x86_64.whl (140 kB)\n",
      "Collecting h11<0.13,>=0.11\n",
      "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: paramiko in /opt/conda/lib/python3.9/site-packages (from gradio==3.11->-r requirements.txt.1 (line 15)) (2.12.0)\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.5.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "Collecting ffmpy\n",
      "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "Collecting pydantic\n",
      "  Downloading pydantic-1.10.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting tensorboard>=1.15.0\n",
      "  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /opt/conda/lib/python3.9/site-packages (from streamlit>=0.73.1->-r requirements.txt.1 (line 10)) (4.4.0)\n",
      "Collecting python-dateutil\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting validators>=0.2\n",
      "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
      "Collecting watchdog\n",
      "  Downloading watchdog-2.3.1-py3-none-manylinux2014_x86_64.whl (80 kB)\n",
      "Collecting blinker>=1.0.0\n",
      "  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n",
      "Collecting pyarrow>=4.0\n",
      "  Downloading pyarrow-11.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
      "Collecting tzlocal>=1.1\n",
      "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
      "Collecting cachetools>=4.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting semver\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting pympler>=0.9\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "Collecting protobuf<4,>=3.12\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.9/site-packages (from streamlit>=0.73.1->-r requirements.txt.1 (line 10)) (13.0.1)\n",
      "Collecting tornado>=6.0.3\n",
      "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
      "Collecting altair>=3.2.0\n",
      "  Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "Collecting importlib-metadata>=1.4\n",
      "  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
      "Collecting gitpython!=3.1.19\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.9/site-packages (from streamlit>=0.73.1->-r requirements.txt.1 (line 10)) (8.1.3)\n",
      "Collecting dill<0.3.7,>=0.3.0\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "Requirement already satisfied: contexttimer in /opt/conda/lib/python3.9/site-packages (from colossalai->-r requirements.txt.1 (line 17)) (0.3.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from colossalai->-r requirements.txt.1 (line 17)) (5.9.4)\n",
      "Requirement already satisfied: fabric in /opt/conda/lib/python3.9/site-packages (from colossalai->-r requirements.txt.1 (line 17)) (2.7.1)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.9/site-packages (from colossalai->-r requirements.txt.1 (line 17)) (1.11.1)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/lib/python3.9/site-packages (from colossalai->-r requirements.txt.1 (line 17)) (2.21.0)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.9/site-packages (from altair>=3.2.0->streamlit>=0.73.1->-r requirements.txt.1 (line 10)) (0.12.0)\n",
      "Collecting jsonschema>=3.0\n",
      "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "Collecting entrypoints\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->gradio==3.11->-r requirements.txt.1 (line 15)) (2.0.4)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil->streamlit>=0.73.1->-r requirements.txt.1 (line 10)) (1.16.0)\n",
      "Collecting scikit-learn>=0.19.1\n",
      "  Downloading scikit_learn-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.19.2->-r requirements.txt.1 (line 12)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.19.2->-r requirements.txt.1 (line 12)) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.19.2->-r requirements.txt.1 (line 12)) (2022.12.7)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.9/site-packages (from rich>=10.11.0->streamlit>=0.73.1->-r requirements.txt.1 (line 10)) (0.9.1)\n",
      "Collecting lazy_loader>=0.1\n",
      "  Downloading lazy_loader-0.1-py3-none-any.whl (8.6 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "Collecting networkx>=2.8\n",
      "  Downloading networkx-3.0-py3-none-any.whl (2.0 MB)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2023.2.28-py3-none-any.whl (216 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.1-py2.py3-none-any.whl (177 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=1.15.0->test-tube>=0.7.5->-r requirements.txt.1 (line 9)) (0.37.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=1.15.0->test-tube>=0.7.5->-r requirements.txt.1 (line 9)) (61.2.0)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.51.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting decorator>=3.4.0\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: pathlib2 in /opt/conda/lib/python3.9/site-packages (from fabric->colossalai->-r requirements.txt.1 (line 17)) (2.3.7.post1)\n",
      "Requirement already satisfied: invoke<2.0,>=1.3 in /opt/conda/lib/python3.9/site-packages (from fabric->colossalai->-r requirements.txt.1 (line 17)) (1.7.3)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from paramiko->gradio==3.11->-r requirements.txt.1 (line 15)) (1.5.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /opt/conda/lib/python3.9/site-packages (from paramiko->gradio==3.11->-r requirements.txt.1 (line 15)) (4.0.1)\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.9/site-packages (from paramiko->gradio==3.11->-r requirements.txt.1 (line 15)) (36.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography>=2.5->paramiko->gradio==3.11->-r requirements.txt.1 (line 15)) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio==3.11->-r requirements.txt.1 (line 15)) (2.21)\n",
      "Collecting starlette<0.26.0,>=0.25.0\n",
      "  Downloading starlette-0.25.0-py3-none-any.whl (66 kB)\n",
      "Collecting anyio<5,>=3.4.0\n",
      "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "Collecting sniffio>=1.1\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting wcwidth>=0.2.5\n",
      "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
      "Collecting httpcore<0.17.0,>=0.15.0\n",
      "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "Collecting rfc3986[idna2008]<2,>=1.3\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting httpcore<0.17.0,>=0.15.0\n",
      "  Downloading httpcore-0.16.2-py3-none-any.whl (68 kB)\n",
      "  Downloading httpcore-0.16.1-py3-none-any.whl (68 kB)\n",
      "  Downloading httpcore-0.16.0-py3-none-any.whl (68 kB)\n",
      "  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting linkify-it-py<3,>=1\n",
      "  Downloading linkify_it_py-2.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting mdit-py-plugins\n",
      "  Downloading mdit_py_plugins-0.3.4-py3-none-any.whl (52 kB)\n",
      "Collecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai->-r requirements.txt.1 (line 17)) (1.7.0)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai->-r requirements.txt.1 (line 17)) (20.17.1)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai->-r requirements.txt.1 (line 17)) (3.3.1)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai->-r requirements.txt.1 (line 17)) (2.5.12)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.9/site-packages (from virtualenv>=20.10.0->pre-commit->colossalai->-r requirements.txt.1 (line 17)) (0.3.6)\n",
      "Requirement already satisfied: platformdirs<3,>=2.4 in /opt/conda/lib/python3.9/site-packages (from virtualenv>=20.10.0->pre-commit->colossalai->-r requirements.txt.1 (line 17)) (2.6.2)\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2022.7-py2.py3-none-any.whl (340 kB)\n",
      "Building wheels for collected packages: pudb, antlr4-python3-runtime, prefetch-generator, test-tube, urwid, validators, ffmpy, future\n",
      "  Building wheel for pudb (setup.py): started\n",
      "  Building wheel for pudb (setup.py): finished with status 'done'\n",
      "  Created wheel for pudb: filename=pudb-2019.2-py3-none-any.whl size=63238 sha256=abde140de4122c830ddd881fe99dc5bdc18b6897863db2e6a283aad9b5b9832b\n",
      "  Stored in directory: /root/.cache/pip/wheels/7d/f4/75/2c0cf51c3cde5e6eac4616bdf264d64cb506a9ddfbb283e398\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=68e96a61afbf51b0fc561d8a6685496054ada8e22429e2e669f97180b6b28ccb\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/3c/ae/14db087e6018de74810afe32eb6ac890ef9c68ba19b00db97a\n",
      "  Building wheel for prefetch-generator (setup.py): started\n",
      "  Building wheel for prefetch-generator (setup.py): finished with status 'done'\n",
      "  Created wheel for prefetch-generator: filename=prefetch_generator-1.0.3-py3-none-any.whl size=4775 sha256=1e306a7f96ba692e7c504b19c9cd6d9e4dd533f5170b8a519f26d092269895cf\n",
      "  Stored in directory: /root/.cache/pip/wheels/75/7d/6f/15ba1f222cc49b38615226345b5c83a85b26c1f353fd061038\n",
      "  Building wheel for test-tube (setup.py): started\n",
      "  Building wheel for test-tube (setup.py): finished with status 'done'\n",
      "  Created wheel for test-tube: filename=test_tube-0.7.5-py3-none-any.whl size=25356 sha256=5acb1bd1f4c6e96aae9682dc37067b199bb07cd690c783d64499d87baaa8ca96\n",
      "  Stored in directory: /root/.cache/pip/wheels/67/58/3f/e21fc7e325685fffc4b9b866f3be18d7a208f34ff5f847f3d5\n",
      "  Building wheel for urwid (setup.py): started\n",
      "  Building wheel for urwid (setup.py): finished with status 'done'\n",
      "  Created wheel for urwid: filename=urwid-2.1.2-cp39-cp39-linux_x86_64.whl size=242262 sha256=6f4cee2fd4798299bd6325c22fb819b278125d96722db55990f477337ba23bf7\n",
      "  Stored in directory: /root/.cache/pip/wheels/44/ec/04/2c1080c3ee4e80e76d662ac35f0594a2a86f9df12095b05cb3\n",
      "  Building wheel for validators (setup.py): started\n",
      "  Building wheel for validators (setup.py): finished with status 'done'\n",
      "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=9be049d315ab77fd7326b4e66f0e37d2701fb0deba126d21aa28aaab3f071b22\n",
      "  Stored in directory: /root/.cache/pip/wheels/2d/f0/a8/1094fca7a7e5d0d12ff56e0c64675d72aa5cc81a5fc200e849\n",
      "  Building wheel for ffmpy (setup.py): started\n",
      "  Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4712 sha256=6838a79d509562c7fc6581a97f3df0fb88028fba2c106556641afbf66d54515a\n",
      "  Stored in directory: /root/.cache/pip/wheels/91/e2/96/f676aa08bfd789328c6576cd0f1fde4a3d686703bb0c247697\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492037 sha256=2ee539415cf95a509c1deacc0e34321ea2946df271a260b6aab05706356ca081\n",
      "  Stored in directory: /root/.cache/pip/wheels/bf/5d/6a/2e53874f7ec4e2bede522385439531fafec8fafe005b5c3d1b\n",
      "Successfully built pudb antlr4-python3-runtime prefetch-generator test-tube urwid validators ffmpy future\n",
      "Installing collected packages: pyasn1, zipp, sniffio, rsa, pyasn1-modules, oauthlib, multidict, mdurl, frozenlist, cachetools, yarl, uc-micro-py, tzdata, threadpoolctl, smmap, scipy, rfc3986, requests-oauthlib, pytz, python-dateutil, pyrsistent, MarkupSafe, markdown-it-py, joblib, importlib-metadata, h11, google-auth, attrs, async-timeout, anyio, aiosignal, werkzeug, wcwidth, tifffile, tensorboard-plugin-wit, tensorboard-data-server, starlette, scikit-learn, PyWavelets, pytz-deprecation-shim, pyparsing, pydantic, protobuf, pandas, opencv-python-headless, networkx, mdit-py-plugins, markdown, linkify-it-py, lazy-loader, kiwisolver, jsonschema, jinja2, importlib-resources, imageio, httpcore, grpcio, google-auth-oauthlib, gitdb, fsspec, fonttools, entrypoints, dill, decorator, cycler, contourpy, aiohttp, absl-py, xxhash, websockets, watchdog, validators, uvicorn, urwid, tzlocal, tornado, toml, tokenizers, tensorboard, semver, scikit-image, responses, regex, qudida, python-multipart, pympler, pydub, pydeck, pycryptodome, pyarrow, orjson, multiprocess, matplotlib, huggingface-hub, httpx, gitpython, future, ftfy, ffmpy, fastapi, braceexpand, blinker, antlr4-python3-runtime, altair, webdataset, transformers, torchmetrics, test-tube, streamlit, pudb, prefetch-generator, opencv-python, open-clip-torch, omegaconf, latent-diffusion, imageio-ffmpeg, gradio, einops, datasets, albumentations\n",
      "  Running setup.py develop for latent-diffusion\n",
      "Successfully installed MarkupSafe-2.1.2 PyWavelets-1.4.1 absl-py-1.4.0 aiohttp-3.8.4 aiosignal-1.3.1 albumentations-1.3.0 altair-4.2.2 antlr4-python3-runtime-4.8 anyio-3.6.2 async-timeout-4.0.2 attrs-22.2.0 blinker-1.5 braceexpand-0.1.7 cachetools-5.3.0 contourpy-1.0.7 cycler-0.11.0 datasets-2.10.1 decorator-5.1.1 dill-0.3.6 einops-0.3.0 entrypoints-0.4 fastapi-0.92.0 ffmpy-0.3.0 fonttools-4.38.0 frozenlist-1.3.3 fsspec-2023.1.0 ftfy-6.1.1 future-0.18.3 gitdb-4.0.10 gitpython-3.1.31 google-auth-2.16.1 google-auth-oauthlib-0.4.6 gradio-3.11.0 grpcio-1.51.3 h11-0.12.0 httpcore-0.15.0 httpx-0.23.3 huggingface-hub-0.12.1 imageio-2.9.0 imageio-ffmpeg-0.4.2 importlib-metadata-6.0.0 importlib-resources-5.12.0 jinja2-3.1.2 joblib-1.2.0 jsonschema-4.17.3 kiwisolver-1.4.4 latent-diffusion-0.0.1 lazy-loader-0.1 linkify-it-py-2.0.0 markdown-3.4.1 markdown-it-py-2.2.0 matplotlib-3.7.0 mdit-py-plugins-0.3.4 mdurl-0.1.2 multidict-6.0.4 multiprocess-0.70.14 networkx-3.0 oauthlib-3.2.2 omegaconf-2.1.1 open-clip-torch-2.7.0 opencv-python-4.6.0.66 opencv-python-headless-4.7.0.72 orjson-3.8.7 pandas-1.5.3 prefetch-generator-1.0.3 protobuf-3.20.3 pudb-2019.2 pyarrow-11.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycryptodome-3.17 pydantic-1.10.5 pydeck-0.8.0 pydub-0.25.1 pympler-1.0.1 pyparsing-3.0.9 pyrsistent-0.19.3 python-dateutil-2.8.2 python-multipart-0.0.6 pytz-2022.7.1 pytz-deprecation-shim-0.1.0.post0 qudida-0.0.4 regex-2022.10.31 requests-oauthlib-1.3.1 responses-0.18.0 rfc3986-1.5.0 rsa-4.9 scikit-image-0.20.0 scikit-learn-1.2.1 scipy-1.9.1 semver-2.13.0 smmap-5.0.0 sniffio-1.3.0 starlette-0.25.0 streamlit-1.19.0 tensorboard-2.12.0 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 test-tube-0.7.5 threadpoolctl-3.1.0 tifffile-2023.2.28 tokenizers-0.12.1 toml-0.10.2 torchmetrics-0.6.0 tornado-6.2 transformers-4.19.2 tzdata-2022.7 tzlocal-4.2 uc-micro-py-1.0.1 urwid-2.1.2 uvicorn-0.20.0 validators-0.20.0 watchdog-2.3.1 wcwidth-0.2.6 webdataset-0.2.5 websockets-10.4 werkzeug-2.2.3 xxhash-3.2.0 yarl-1.8.2 zipp-3.15.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mCollecting lightning\n",
      "  Downloading lightning-1.9.3-py3-none-any.whl (2.1 MB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.26.82-py3-none-any.whl (134 kB)\n",
      "Collecting traitlets<7.0,>=5.3.0\n",
      "  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
      "Requirement already satisfied: Jinja2<5.0 in /opt/conda/lib/python3.9/site-packages (from lightning) (3.1.2)\n",
      "Requirement already satisfied: PyYAML<8.0 in /opt/conda/lib/python3.9/site-packages (from lightning) (6.0)\n",
      "Collecting deepdiff<8.0,>=5.7.0\n",
      "  Downloading deepdiff-6.2.3-py3-none-any.whl (73 kB)\n",
      "Collecting arrow<3.0,>=1.2.0\n",
      "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /opt/conda/lib/python3.9/site-packages (from lightning) (4.4.0)\n",
      "Requirement already satisfied: urllib3<3.0 in /opt/conda/lib/python3.9/site-packages (from lightning) (1.26.8)\n",
      "Requirement already satisfied: rich<15.0 in /opt/conda/lib/python3.9/site-packages (from lightning) (13.0.1)\n",
      "Collecting torchmetrics<2.0,>=0.7.0\n",
      "  Downloading torchmetrics-0.11.3-py3-none-any.whl (518 kB)\n",
      "Requirement already satisfied: fsspec<2024.0,>=2022.5.0 in /opt/conda/lib/python3.9/site-packages (from lightning) (2023.1.0)\n",
      "Collecting lightning-cloud>=0.5.26\n",
      "  Downloading lightning_cloud-0.5.31-py3-none-any.whl (539 kB)\n",
      "Requirement already satisfied: uvicorn<2.0 in /opt/conda/lib/python3.9/site-packages (from lightning) (0.20.0)\n",
      "Requirement already satisfied: psutil<7.0 in /opt/conda/lib/python3.9/site-packages (from lightning) (5.9.4)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.9/site-packages (from lightning) (4.63.0)\n",
      "Requirement already satisfied: torch<3.0,>=1.10.0 in /opt/conda/lib/python3.9/site-packages (from lightning) (1.12.1)\n",
      "Requirement already satisfied: pydantic<3.0 in /opt/conda/lib/python3.9/site-packages (from lightning) (1.10.5)\n",
      "Requirement already satisfied: websockets<12.0 in /opt/conda/lib/python3.9/site-packages (from lightning) (10.4)\n",
      "Collecting lightning-utilities<2.0,>=0.6.0.post0\n",
      "  Downloading lightning_utilities-0.7.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: starlette<2.0 in /opt/conda/lib/python3.9/site-packages (from lightning) (0.25.0)\n",
      "Collecting fastapi<0.89.0\n",
      "  Downloading fastapi-0.88.0-py3-none-any.whl (55 kB)\n",
      "Collecting websocket-client<3.0\n",
      "  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: packaging<25.0,>=17.1 in /opt/conda/lib/python3.9/site-packages (from lightning) (23.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.9/site-packages (from lightning) (1.22.3)\n",
      "Collecting dateutils<2.0\n",
      "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: click<10.0 in /opt/conda/lib/python3.9/site-packages (from lightning) (8.1.3)\n",
      "Collecting inquirer<5.0,>=2.10.0\n",
      "  Downloading inquirer-3.1.2-py3-none-any.whl (17 kB)\n",
      "Collecting croniter<1.4.0,>=1.3.0\n",
      "  Downloading croniter-1.3.8-py2.py3-none-any.whl (18 kB)\n",
      "Collecting starsessions<2.0,>=1.2.1\n",
      "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests<4.0 in /opt/conda/lib/python3.9/site-packages (from lightning) (2.27.1)\n",
      "Collecting beautifulsoup4<6.0,>=4.8.0\n",
      "  Downloading beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "Collecting botocore<1.30.0,>=1.29.82\n",
      "  Downloading botocore-1.29.82-py3-none-any.whl (10.5 MB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/lib/python3.9/site-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.4-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.9/site-packages (from dateutils<2.0->lightning) (2022.7.1)\n",
      "Collecting ordered-set<4.2.0,>=4.0.2\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: orjson in /opt/conda/lib/python3.9/site-packages (from deepdiff<8.0,>=5.7.0->lightning) (3.8.7)\n",
      "Collecting starlette<2.0\n",
      "  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.9/site-packages (from starlette<2.0->lightning) (3.6.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning) (3.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.9/site-packages (from fsspec<2024.0,>=2022.5.0->lightning) (3.8.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (2.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (4.0.2)\n",
      "Collecting blessed>=1.19.0\n",
      "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting readchar>=3.0.6\n",
      "  Downloading readchar-4.0.3-py3-none-any.whl (8.4 kB)\n",
      "Collecting python-editor>=1.0.4\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.9/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (1.16.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.9/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from Jinja2<5.0->lightning) (2.1.2)\n",
      "Collecting pyjwt\n",
      "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: fastapi[all] in /opt/conda/lib/python3.9/site-packages (from lightning-cloud>=0.5.26->lightning) (0.92.0)\n",
      "Requirement already satisfied: setuptools>=41.0 in /opt/conda/lib/python3.9/site-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning) (61.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<4.0->lightning) (2022.12.7)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.9/site-packages (from rich<15.0->lightning) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.9/site-packages (from rich<15.0->lightning) (2.14.0)\n",
      "Collecting itsdangerous<3.0.0,>=2.0.1\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.9/site-packages (from uvicorn<2.0->lightning) (0.12.0)\n",
      "Collecting fastapi[all]\n",
      "  Downloading fastapi-0.91.0-py3-none-any.whl (56 kB)\n",
      "  Downloading fastapi-0.90.1-py3-none-any.whl (56 kB)\n",
      "  Downloading fastapi-0.90.0-py3-none-any.whl (56 kB)\n",
      "  Downloading fastapi-0.89.1-py3-none-any.whl (55 kB)\n",
      "  Downloading fastapi-0.89.0-py3-none-any.whl (55 kB)\n",
      "Collecting email-validator>=1.1.1\n",
      "  Downloading email_validator-1.3.1-py2.py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: python-multipart>=0.0.5 in /opt/conda/lib/python3.9/site-packages (from fastapi<0.89.0->lightning) (0.0.6)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1\n",
      "  Downloading ujson-5.7.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from fastapi<0.89.0->lightning) (0.23.3)\n",
      "Collecting dnspython>=1.15.0\n",
      "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /opt/conda/lib/python3.9/site-packages (from httpx>=0.23.0->fastapi<0.89.0->lightning) (1.5.0)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /opt/conda/lib/python3.9/site-packages (from httpx>=0.23.0->fastapi<0.89.0->lightning) (0.15.0)\n",
      "Collecting httptools>=0.5.0\n",
      "  Downloading httptools-0.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (417 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Downloading uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
      "Collecting watchfiles>=0.13\n",
      "  Downloading watchfiles-0.18.1-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: watchfiles, uvloop, starlette, python-dotenv, httptools, dnspython, ujson, jmespath, itsdangerous, fastapi, email-validator, websocket-client, soupsieve, readchar, python-editor, pyjwt, ordered-set, botocore, blessed, traitlets, torchmetrics, starsessions, s3transfer, lightning-utilities, lightning-cloud, inquirer, deepdiff, dateutils, croniter, beautifulsoup4, arrow, lightning, boto3\n",
      "  Attempting uninstall: starlette\n",
      "    Found existing installation: starlette 0.25.0\n",
      "    Uninstalling starlette-0.25.0:\n",
      "      Successfully uninstalled starlette-0.25.0\n",
      "  Attempting uninstall: fastapi\n",
      "    Found existing installation: fastapi 0.92.0\n",
      "    Uninstalling fastapi-0.92.0:\n",
      "      Successfully uninstalled fastapi-0.92.0\n",
      "  Attempting uninstall: torchmetrics\n",
      "    Found existing installation: torchmetrics 0.6.0\n",
      "    Uninstalling torchmetrics-0.6.0:\n",
      "      Successfully uninstalled torchmetrics-0.6.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mSuccessfully installed arrow-1.2.3 beautifulsoup4-4.11.2 blessed-1.20.0 boto3-1.26.82 botocore-1.29.82 croniter-1.3.8 dateutils-0.6.12 deepdiff-6.2.3 dnspython-2.3.0 email-validator-1.3.1 fastapi-0.88.0 httptools-0.5.0 inquirer-3.1.2 itsdangerous-2.1.2 jmespath-1.0.1 lightning-1.9.3 lightning-cloud-0.5.31 lightning-utilities-0.7.1 ordered-set-4.1.0 pyjwt-2.6.0 python-dotenv-1.0.0 python-editor-1.0.4 readchar-4.0.3 s3transfer-0.6.0 soupsieve-2.4 starlette-0.22.0 starsessions-1.3.0 torchmetrics-0.11.3 traitlets-5.9.0 ujson-5.7.0 uvloop-0.17.0 watchfiles-0.18.1 websocket-client-1.5.1\n",
      "Removing intermediate container e26b257099f5\n",
      " ---> c72af6f67e5b\n",
      "Step 13/18 : RUN git clone https://github.com/hpcaitech/ColossalAI.git /opt/ml/ColossalAI\n",
      " ---> Running in b0b6658320de\n",
      "\u001b[91mCloning into '/opt/ml/ColossalAI'...\n",
      "\u001b[0mRemoving intermediate container b0b6658320de\n",
      " ---> a31b9ff36963\n",
      "Step 14/18 : RUN cd /opt/ml/ColossalAI && pip install -e .\n",
      " ---> Running in 9b8495fd7053\n",
      "Obtaining file:///opt/ml/ColossalAI\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from colossalai==0.2.5) (1.22.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from colossalai==0.2.5) (4.63.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from colossalai==0.2.5) (5.9.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from colossalai==0.2.5) (23.0)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/lib/python3.9/site-packages (from colossalai==0.2.5) (2.21.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.9/site-packages (from colossalai==0.2.5) (13.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from colossalai==0.2.5) (8.1.3)\n",
      "Requirement already satisfied: fabric in /opt/conda/lib/python3.9/site-packages (from colossalai==0.2.5) (2.7.1)\n",
      "Requirement already satisfied: contexttimer in /opt/conda/lib/python3.9/site-packages (from colossalai==0.2.5) (0.3.3)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.9/site-packages (from colossalai==0.2.5) (1.11.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (from colossalai==0.2.5) (1.12.1)\n",
      "Requirement already satisfied: pathlib2 in /opt/conda/lib/python3.9/site-packages (from fabric->colossalai==0.2.5) (2.3.7.post1)\n",
      "Requirement already satisfied: paramiko>=2.4 in /opt/conda/lib/python3.9/site-packages (from fabric->colossalai==0.2.5) (2.12.0)\n",
      "Requirement already satisfied: invoke<2.0,>=1.3 in /opt/conda/lib/python3.9/site-packages (from fabric->colossalai==0.2.5) (1.7.3)\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.4->fabric->colossalai==0.2.5) (36.0.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.4->fabric->colossalai==0.2.5) (1.16.0)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.4->fabric->colossalai==0.2.5) (1.5.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.4->fabric->colossalai==0.2.5) (4.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography>=2.5->paramiko>=2.4->fabric->colossalai==0.2.5) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.5->paramiko>=2.4->fabric->colossalai==0.2.5) (2.21)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai==0.2.5) (3.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai==0.2.5) (6.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai==0.2.5) (2.5.12)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai==0.2.5) (20.17.1)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai==0.2.5) (1.7.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from nodeenv>=0.11.1->pre-commit->colossalai==0.2.5) (61.2.0)\n",
      "Requirement already satisfied: platformdirs<3,>=2.4 in /opt/conda/lib/python3.9/site-packages (from virtualenv>=20.10.0->pre-commit->colossalai==0.2.5) (2.6.2)\n",
      "Requirement already satisfied: filelock<4,>=3.4.1 in /opt/conda/lib/python3.9/site-packages (from virtualenv>=20.10.0->pre-commit->colossalai==0.2.5) (3.9.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.9/site-packages (from virtualenv>=20.10.0->pre-commit->colossalai==0.2.5) (0.3.6)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.9/site-packages (from rich->colossalai==0.2.5) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.9/site-packages (from rich->colossalai==0.2.5) (2.14.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.9/site-packages (from torch->colossalai==0.2.5) (4.4.0)\n",
      "Installing collected packages: colossalai\n",
      "  Attempting uninstall: colossalai\n",
      "    Found existing installation: colossalai 0.2.0+torch1.12cu11.3\n",
      "    Uninstalling colossalai-0.2.0+torch1.12cu11.3:\n",
      "      Successfully uninstalled colossalai-0.2.0+torch1.12cu11.3\n",
      "  Running setup.py develop for colossalai\n",
      "Successfully installed colossalai-0.2.5\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 9b8495fd7053\n",
      " ---> 8eafc2bf7908\n",
      "Step 15/18 : RUN wget https://github.com/peak/s5cmd/releases/download/v2.0.0/s5cmd_2.0.0_Linux-64bit.tar.gz && tar -zxvf s5cmd_2.0.0_Linux-64bit.tar.gz\n",
      " ---> Running in 0f591b713a3e\n",
      "\u001b[91m--2023-03-02 12:39:04--  https://github.com/peak/s5cmd/releases/download/v2.0.0/s5cmd_2.0.0_Linux-64bit.tar.gz\n",
      "\u001b[0m\u001b[91mResolving github.com (github.com)... \u001b[0m\u001b[91m192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... \u001b[0m\u001b[91mconnected.\n",
      "\u001b[0m\u001b[91mHTTP request sent, awaiting response... \u001b[0m\u001b[91m302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/73909333/2e177ae0-614f-48ba-92fd-04cf9bf41529?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230302%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230302T123904Z&X-Amz-Expires=300&X-Amz-Signature=25be886c7d458ee19586fb409889c1dd5fd083841017fbffab529e798bc1e6ea&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=73909333&response-content-disposition=attachment%3B%20filename%3Ds5cmd_2.0.0_Linux-64bit.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-03-02 12:39:04--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/73909333/2e177ae0-614f-48ba-92fd-04cf9bf41529?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230302%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230302T123904Z&X-Amz-Expires=300&X-Amz-Signature=25be886c7d458ee19586fb409889c1dd5fd083841017fbffab529e798bc1e6ea&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=73909333&response-content-disposition=attachment%3B%20filename%3Ds5cmd_2.0.0_Linux-64bit.tar.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... \u001b[0m\u001b[91m185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... \u001b[0m\u001b[91mconnected.\n",
      "\u001b[0m\u001b[91mHTTP request sent, awaiting response... \u001b[0m\u001b[91m200 OK\n",
      "\u001b[0m\u001b[91mLength: 4276789 (4.1M) [application/octet-stream]\n",
      "\u001b[0m\u001b[91mSaving to: ‘s5cmd_2.0.0_Linux-64bit.tar.gz’\n",
      "\u001b[0m\u001b[91m\n",
      "     0K ..\u001b[0m\u001b[91m....\u001b[0m\u001b[91m...\u001b[0m\u001b[91m. ..\u001b[0m\u001b[91m...\u001b[0m\u001b[91m..... ....\u001b[0m\u001b[91m...... ..\u001b[0m\u001b[91m..\u001b[0m\u001b[91m...... ...\u001b[0m\u001b[91m....\u001b[0m\u001b[91m...  1%  380K 11s\n",
      "    50K .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m.....  2%  753K 8s\n",
      "   100K .......... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m.......  3%  760K 7s\n",
      "   150K .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m.........  4%  760K 7s\n",
      "   200K .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .......... ..........  5% 86.5M 5s\n",
      "   250K .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... \u001b[0m\u001b[91m.......\u001b[0m\u001b[91m... ..........  7%  763K 5s\n",
      "   300K ...\u001b[0m\u001b[91m....... .......... .......... .....\u001b[0m\u001b[91m..... ..........  8% 50.1M 4s\n",
      "   350K .........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .......... .......... .........\u001b[0m\u001b[91m.  9%  752K 4s\n",
      "   400K .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... .......... 10% 78.8M 4s\n",
      "   450K .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... 11%  787K 4s\n",
      "   500K .......... .......... .......\u001b[0m\u001b[91m... .......... .......... 13%  135M 3s\n",
      "   550K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... 14% 59.4M 3s\n",
      "   600K .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... 15% 7.61M 3s\n",
      "   650K .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... .......... .....\u001b[0m\u001b[91m..... 16%\u001b[0m\u001b[91m  842K 3s\n",
      "   700K ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... 17%  182M 3s\n",
      "   750K .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .......... 19% 61.1M 3s\n",
      "   800K .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... .......... .........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... 20% 71.4M 2s\n",
      "   850K .......... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... 21%  227M 2s\n",
      "   900K ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... .......... 22%  788K 2s\n",
      "   950K .........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. 23%  233M 2s\n",
      "  1000K .......... .....\u001b[0m\u001b[91m..... .......... .........\u001b[0m\u001b[91m. .......... 25%  151M 2s\n",
      "  1050K .......... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... 26%  102M 2s\n",
      "  1100K ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......... .......... ...\u001b[0m\u001b[91m....... 27%  127M 2s\n",
      "  1150K .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. 28%  174M 2s\n",
      "  1200K .......... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... 29%  111M 2s\n",
      "  1250K .......... ...\u001b[0m\u001b[91m....... .......... .......... .....\u001b[0m\u001b[91m..... 31%  784K 2s\n",
      "  1300K .......... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... 32%  108M 2s\n",
      "  1350K .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... .......... 33%  167M 1s\n",
      "  1400K .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... 34%  216M 1s\n",
      "  1450K .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... 35%  195M 1s\n",
      "  1500K ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... 37%  243M 1s\n",
      "  1550K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .......... .......... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. 38%  178M 1s\n",
      "  1600K .......... .......... .......... .......... .......... 39%  302M 1s\n",
      "  1650K .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... 40%  223M 1s\n",
      "  1700K .......... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... 41%  783K 1s\n",
      "  1750K .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... 43%  190M 1s\n",
      "  1800K .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... 44%  195M 1s\n",
      "  1850K .......... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... 45%  192M 1s\n",
      "  1900K ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... 46%  188M 1s\n",
      "  1950K .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. 47%  155M 1s\n",
      "  2000K .......... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... 49%  179M 1s\n",
      "  2050K .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... 50%  215M 1s\n",
      "  2100K .......... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... .......... 51%  189M 1s\n",
      "  2150K .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... 52%  184M 1s\n",
      "  2200K .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... 53%  254M 1s\n",
      "  2250K .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... 55%  281M 1s\n",
      "  2300K ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... 56%  791K 1s\n",
      "  2350K .........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .......... 57%  122M 1s\n",
      "  2400K .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... 58%  189M 1s\n",
      "  2450K .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... 59%  167M 1s\n",
      "  2500K .......... .......... .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... 61%  230M 1s\n",
      "  2550K .........\u001b[0m\u001b[91m. .......... .......... .......... .\u001b[0m\u001b[91m......... 62%  174M 1s\n",
      "  2600K .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... 63%  193M 0s\n",
      "  2650K .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... 64%  212M 0s\n",
      "  2700K ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... 65%  226M 0s\n",
      "  2750K .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. 67%  194M 0s\n",
      "  2800K .......... .....\u001b[0m\u001b[91m..... .......... .........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... 68%  311M 0s\n",
      "  2850K .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... 69%  252M 0s\n",
      "  2900K .......... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... 70%  229M 0s\n",
      "  2950K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... 71%  217M 0s\n",
      "  3000K .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... 73%  267M 0s\n",
      "  3050K .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .......... 74%  231M 0s\n",
      "  3100K ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... 75%  804K 0s\n",
      "  3150K .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. 76%  145M 0s\n",
      "  3200K .......... .......... .......... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... 77%  240M 0s\n",
      "  3250K .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... 79%  209M 0s\n",
      "  3300K ...\u001b[0m\u001b[91m....... .......... .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... 80%  199M 0s\n",
      "  3350K .........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... 81%  189M 0s\n",
      "  3400K .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... 82%  215M 0s\n",
      "  3450K .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... 83%  216M 0s\n",
      "  3500K ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... 84%\u001b[0m\u001b[91m  182M 0s\n",
      "  3550K .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. 86%  179M 0s\n",
      "  3600K .......... .....\u001b[0m\u001b[91m..... .......... .......... .......... 87%  255M 0s\n",
      "  3650K .......... .......... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... 88%  281M 0s\n",
      "  3700K ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... 89%  219M 0s\n",
      "  3750K .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. 90%  206M 0s\n",
      "  3800K .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......... 92%  195M 0s\n",
      "  3850K .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... 93%  233M 0s\n",
      "  3900K ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... 94%  245M 0s\n",
      "  3950K .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. 95% 12.4M 0s\n",
      "  4000K .......... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... 96%  230M 0s\n",
      "  4050K .....\u001b[0m\u001b[91m..... .......... ........\u001b[0m\u001b[91m.\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m.... 98%  840K 0s\n",
      "  4100K .......... ..\u001b[0m\u001b[91m........ ..\u001b[0m\u001b[91m......\u001b[0m\u001b[91m.. .......... ....\u001b[0m\u001b[91m...... 99%  200M 0s\n",
      "  4150K ..\u001b[0m\u001b[91m........\u001b[0m\u001b[91m .......... ......\u001b[0m\u001b[91m                 \u001b[0m\u001b[91m      \u001b[0m\u001b[91m   \u001b[0m\u001b[91m100%\u001b[0m\u001b[91m  200M=1.0s\n",
      "\n",
      "\u001b[0m\u001b[91m2023-03-02 12:39:05 (4.12 MB/s) - ‘s5cmd_2.0.0_Linux-64bit.tar.gz’ saved [4276789/4276789]\n",
      "\n",
      "\u001b[0mCHANGELOG.md\n",
      "LICENSE\n",
      "README.md\n",
      "s5cmd\n",
      "Removing intermediate container 0f591b713a3e\n",
      " ---> 2701ad6833d8\n",
      "Step 16/18 : ENV HF_DATASETS_OFFLINE=0\n",
      " ---> Running in ff690d45a08b\n",
      "Removing intermediate container ff690d45a08b\n",
      " ---> a7420d8f3673\n",
      "Step 17/18 : ENV TRANSFORMERS_OFFLINE=1\n",
      " ---> Running in fbd8303976a9\n",
      "Removing intermediate container fbd8303976a9\n",
      " ---> 27e09e88b773\n",
      "Step 18/18 : ENV DIFFUSERS_OFFLINE=1\n",
      " ---> Running in b4a558812bf2\n",
      "Removing intermediate container b4a558812bf2\n",
      " ---> cd9e1479f820\n",
      "Successfully built cd9e1479f820\n",
      "Successfully tagged diffusion:latest\n",
      "The push refers to repository [310850127430.dkr.ecr.us-west-2.amazonaws.com/diffusion]\n",
      "\n",
      "\u001b[1B9097660c: Preparing \n",
      "\u001b[1B4339ed6b: Preparing \n",
      "\u001b[1Bddeec15c: Preparing \n",
      "\u001b[1B2099a578: Preparing \n",
      "\u001b[1Bbb626e4b: Preparing \n",
      "\u001b[1B372d77f1: Preparing \n",
      "\u001b[1B8c26bd57: Preparing \n",
      "\u001b[1Be26ccf08: Preparing \n",
      "\u001b[1B1afd9f23: Preparing \n",
      "\u001b[1B373a1616: Preparing \n",
      "\u001b[1B765f19d1: Preparing \n",
      "\u001b[1B9e5817b6: Preparing \n",
      "\u001b[1B44e37d06: Preparing \n",
      "\u001b[1B30efb737: Preparing \n",
      "\u001b[1Beca3d986: Preparing \n",
      "\u001b[1B616d4fb1: Preparing \n",
      "\u001b[1Bac543081: Preparing \n",
      "\u001b[1Bc4c62eef: Preparing \n",
      "\u001b[1Ba71261c7: Preparing \n",
      "\u001b[1Bba43cdbe: Preparing \n",
      "\u001b[1B942867a5: Preparing \n",
      "\u001b[1Bfe6d10a9: Preparing \n",
      "\u001b[1B91182163: Preparing \n",
      "\u001b[1B6c5bb65c: Preparing \n",
      "\u001b[1B550a3bbe: Preparing \n",
      "\u001b[23B099a578: Pushed   1.647GB/1.623GB\u001b[22A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[26A\u001b[2K\u001b[22A\u001b[2K\u001b[26A\u001b[2K\u001b[23A\u001b[2K\u001b[17A\u001b[2K\u001b[14A\u001b[2K\u001b[26A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[23A\u001b[2K\u001b[24A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[26A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[24A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2Klatest: digest: sha256:d374004da87b7083bc538c4d101a4f04cc4d82d7e8f2728ae40f51ace725a284 size: 5809\n"
     ]
    }
   ],
   "source": [
    "!./build_and_push diffusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8164e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a9740e3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker import get_execution_role\n",
    "\n",
    "# role = get_execution_role()\n",
    "# from sagemaker.estimator import Estimator\n",
    "# instance_type = 'local_gpu'\n",
    "# estimator = Estimator(role=role,\n",
    "#                       instance_count=1,\n",
    "#                       instance_type=instance_type,\n",
    "#                       image_uri='diffusion')\n",
    "\n",
    "# estimator.fit('file:///home/ec2-user/SageMaker/colo3/diffusion/train_colossalai_teyvat.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb723d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker:Creating training-job with name: diffusion-2023-03-02-12-56-09-717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-02 12:56:10 Starting - Starting the training job...\n",
      "2023-03-02 12:56:25 Starting - Preparing the instances for training......\n",
      "2023-03-02 12:57:35 Downloading - Downloading input data\n",
      "2023-03-02 12:57:35 Training - Downloading the training image...........................\n",
      "2023-03-02 13:01:46 Training - Training image download completed. Training in progress....\u001b[34mtrain_cmd: ['/opt/conda/bin/python', 'main_1.py', '--train', '--logdir', '/opt/ml/df_model', '--base', 'train_colossalai_teyvat.yaml', '--ckpt', './512-base-ema.ckpt', '-n', 'sd']\u001b[0m\n",
      "\u001b[34mname sd\u001b[0m\n",
      "\u001b[34mresume \u001b[0m\n",
      "\u001b[34mbase ['train_colossalai_teyvat.yaml']\u001b[0m\n",
      "\u001b[34mtrain True\u001b[0m\n",
      "\u001b[34mno_test False\u001b[0m\n",
      "\u001b[34mproject None\u001b[0m\n",
      "\u001b[34mckpt ./512-base-ema.ckpt\u001b[0m\n",
      "\u001b[34mdebug False\u001b[0m\n",
      "\u001b[34mseed 23\u001b[0m\n",
      "\u001b[34mpostfix \u001b[0m\n",
      "\u001b[34mlogdir /opt/ml/df_model\u001b[0m\n",
      "\u001b[34mscale_lr True\u001b[0m\n",
      "\u001b[34mlogger True\u001b[0m\n",
      "\u001b[34menable_checkpointing True\u001b[0m\n",
      "\u001b[34mdefault_root_dir None\u001b[0m\n",
      "\u001b[34mgradient_clip_val None\u001b[0m\n",
      "\u001b[34mgradient_clip_algorithm None\u001b[0m\n",
      "\u001b[34mnum_nodes 1\u001b[0m\n",
      "\u001b[34mnum_processes None\u001b[0m\n",
      "\u001b[34mGlobal seed set to 23\u001b[0m\n",
      "\u001b[34mdevices None\u001b[0m\n",
      "\u001b[34mgpus None\u001b[0m\n",
      "\u001b[34mauto_select_gpus None\u001b[0m\n",
      "\u001b[34mtpu_cores None\u001b[0m\n",
      "\u001b[34mipus None\u001b[0m\n",
      "\u001b[34menable_progress_bar True\u001b[0m\n",
      "\u001b[34moverfit_batches 0.0\u001b[0m\n",
      "\u001b[34mtrack_grad_norm -1\u001b[0m\n",
      "\u001b[34mcheck_val_every_n_epoch 1\u001b[0m\n",
      "\u001b[34mfast_dev_run False\u001b[0m\n",
      "\u001b[34maccumulate_grad_batches None\u001b[0m\n",
      "\u001b[34mmax_epochs None\u001b[0m\n",
      "\u001b[34mmin_epochs None\u001b[0m\n",
      "\u001b[34mmax_steps -1\u001b[0m\n",
      "\u001b[34mmin_steps None\u001b[0m\n",
      "\u001b[34mmax_time None\u001b[0m\n",
      "\u001b[34mlimit_train_batches None\u001b[0m\n",
      "\u001b[34mlimit_val_batches None\u001b[0m\n",
      "\u001b[34mlimit_test_batches None\u001b[0m\n",
      "\u001b[34mlimit_predict_batches None\u001b[0m\n",
      "\u001b[34mval_check_interval None\u001b[0m\n",
      "\u001b[34mlog_every_n_steps 50\u001b[0m\n",
      "\u001b[34maccelerator None\u001b[0m\n",
      "\u001b[34mstrategy None\u001b[0m\n",
      "\u001b[34msync_batchnorm False\u001b[0m\n",
      "\u001b[34mprecision 32\u001b[0m\n",
      "\u001b[34menable_model_summary True\u001b[0m\n",
      "\u001b[34mnum_sanity_val_steps 2\u001b[0m\n",
      "\u001b[34mresume_from_checkpoint None\u001b[0m\n",
      "\u001b[34mprofiler None\u001b[0m\n",
      "\u001b[34mbenchmark None\u001b[0m\n",
      "\u001b[34mreload_dataloaders_every_n_epochs 0\u001b[0m\n",
      "\u001b[34mauto_lr_find False\u001b[0m\n",
      "\u001b[34mreplace_sampler_ddp True\u001b[0m\n",
      "\u001b[34mdetect_anomaly False\u001b[0m\n",
      "\u001b[34mauto_scale_batch_size False\u001b[0m\n",
      "\u001b[34mplugins None\u001b[0m\n",
      "\u001b[34mamp_backend None\u001b[0m\n",
      "\u001b[34mamp_level None\u001b[0m\n",
      "\u001b[34mmove_metrics_to_cpu False\u001b[0m\n",
      "\u001b[34mmultiple_trainloader_mode max_size_cycle\u001b[0m\n",
      "\u001b[34minference_mode True\u001b[0m\n",
      "\u001b[34mlogdir /opt/ml/df_model/2023-03-02T13-02-27_sd\u001b[0m\n",
      "\u001b[34mopt.base ['train_colossalai_teyvat.yaml']\u001b[0m\n",
      "\u001b[34mUsing ckpt_path = ./512-base-ema.ckpt\u001b[0m\n",
      "\u001b[34mconfig.model {'base_learning_rate': 0.0001, 'target': 'ldm.models.diffusion.ddpm.LatentDiffusion', 'params': {'parameterization': 'v', 'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'ckpt': './512-base-ema.ckpt', 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'image', 'cond_stage_key': 'txt', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': False, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'scheduler_config': {'target': 'ldm.lr_scheduler.LambdaLinearScheduler', 'params': {'warm_up_steps': [1], 'cycle_lengths': [10000000000000], 'f_start': [1e-06], 'f_max': [0.0001], 'f_min': [1e-10]}}, 'unet_config': {'target': 'ldm.modules.diffusionmodules.openaimodel.UNetModel', 'params': {'use_checkpoint': True, 'use_fp16': True, 'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_spatial_transformer': True, 'use_linear_in_transformer': True, 'transformer_depth': 1, 'context_dim': 1024, 'legacy': False}}, 'first_stage_config': {'target': 'ldm.models.autoencoder.AutoencoderKL', 'params': {'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}}, 'cond_stage_config': {'target': 'ldm.modules.encoders.modules.FrozenOpenCLIPEmbedder', 'params': {'freeze': True, 'layer': 'penultimate'}}, 'use_fp16': True}}\u001b[0m\n",
      "\u001b[34mNo module 'xformers'. Proceeding without it.\u001b[0m\n",
      "\u001b[34mLatentDiffusion: Running in v-prediction mode\u001b[0m\n",
      "\u001b[34mWorking with z of shape (1, 4, 32, 32) = 4096 dimensions.\u001b[0m\n",
      "\u001b[34m#015Downloading (…)_pytorch_model.bin\";:   0%|          | 0.00/3.94G [00:00<?, ?B/s]#015Downloading (…)_pytorch_model.bin\";:   0%|          | 10.5M/3.94G [00:00<00:48, 80.9MB/s]#015Downloading (…)_pytorch_model.bin\";:   1%|          | 21.0M/3.94G [00:00<00:48, 81.2MB/s]#015Downloading (…)_pytorch_model.bin\";:   1%|          | 31.5M/3.94G [00:00<00:46, 84.0MB/s]#015Downloading (…)_pytorch_model.bin\";:   1%|          | 41.9M/3.94G [00:00<00:49, 79.0MB/s]#015Downloading (…)_pytorch_model.bin\";:   1%|▏         | 52.4M/3.94G [00:00<00:50, 77.0MB/s]#015Downloading (…)_pytorch_model.bin\";:   2%|▏         | 62.9M/3.94G [00:00<00:49, 77.9MB/s]#015Downloading (…)_pytorch_model.bin\";:   2%|▏         | 73.4M/3.94G [00:00<00:48, 79.3MB/s]#015Downloading (…)_pytorch_model.bin\";:   2%|▏         | 83.9M/3.94G [00:01<00:48, 78.9MB/s]#015Downloading (…)_pytorch_model.bin\";:   2%|▏         | 94.4M/3.94G [00:01<00:52, 73.3MB/s]#015Downloading (…)_pytorch_model.bin\";:   3%|▎         | 105M/3.94G [00:01<00:50, 76.7MB/s] #015Downloading (…)_pytorch_model.bin\";:   3%|▎         | 115M/3.94G [00:01<00:49, 76.8MB/s]#015Downloading (…)_pytorch_model.bin\";:   3%|▎         | 126M/3.94G [00:01<00:50, 75.9MB/s]#015Downloading (…)_pytorch_model.bin\";:   3%|▎         | 136M/3.94G [00:01<00:48, 77.8MB/s]#015Downloading (…)_pytorch_model.bin\";:   4%|▎         | 147M/3.94G [00:01<00:47, 80.4MB/s]#015Downloading (…)_pytorch_model.bin\";:   4%|▍         | 157M/3.94G [00:02<00:50, 75.7MB/s]#015Downloading (…)_pytorch_model.bin\";:   4%|▍         | 168M/3.94G [00:02<00:49, 76.3MB/s]#015Downloading (…)_pytorch_model.bin\";:   5%|▍         | 178M/3.94G [00:02<00:49, 76.1MB/s]#015Downloading (…)_pytorch_model.bin\";:   5%|▍         | 189M/3.94G [00:02<00:48, 77.1MB/s]#015Downloading (…)_pytorch_model.bin\";:   5%|▌         | 199M/3.94G [00:02<00:51, 73.2MB/s]#015Downloading (…)_pytorch_model.bin\";:   5%|▌         | 210M/3.94G [00:02<00:51, 72.0MB/s]#015Downloading (…)_pytorch_model.bin\";:   6%|▌         | 220M/3.94G [00:02<00:51, 72.5MB/s]#015Downloading (…)_pytorch_model.bin\";:   6%|▌         | 231M/3.94G [00:03<00:50, 73.3MB/s]#015Downloading (…)_pytorch_model.bin\";:   6%|▌         | 241M/3.94G [00:03<00:53, 69.2MB/s]#015Downloading (…)_pytorch_model.bin\";:   6%|▋         | 252M/3.94G [00:03<00:53, 69.4MB/s]#015Downloading (…)_pytorch_model.bin\";:   7%|▋         | 262M/3.94G [00:03<00:56, 65.5MB/s]#015Downloading (…)_pytorch_model.bin\";:   7%|▋         | 273M/3.94G [00:03<00:54, 67.8MB/s]#015Downloading (…)_pytorch_model.bin\";:   7%|▋         | 283M/3.94G [00:03<00:52, 69.2MB/s]#015Downloading (…)_pytorch_model.bin\";:   7%|▋         | 294M/3.94G [00:03<00:50, 72.2MB/s]#015Downloading (…)_pytorch_model.bin\";:   8%|▊         | 304M/3.94G [00:04<00:50, 72.5MB/s]#015Downloading (…)_pytorch_model.bin\";:   8%|▊         | 315M/3.94G [00:04<00:57, 63.0MB/s]#015Downloading (…)_pytorch_model.bin\";:   8%|▊         | 325M/3.94G [00:04<00:53, 67.2MB/s]#015Downloading (…)_pytorch_model.bin\";:   9%|▊         | 336M/3.94G [00:04<00:50, 71.5MB/s]#015Downloading (…)_pytorch_model.bin\";:   9%|▉         | 346M/3.94G [00:04<00:48, 73.7MB/s]#015Downloading (…)_pytorch_model.bin\";:   9%|▉         | 357M/3.94G [00:04<00:50, 70.7MB/s]#015Downloading (…)_pytorch_model.bin\";:   9%|▉         | 367M/3.94G [00:05<00:55, 64.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  10%|▉         | 377M/3.94G [00:05<00:53, 67.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  10%|▉         | 388M/3.94G [00:05<00:52, 67.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  10%|█         | 398M/3.94G [00:05<00:52, 68.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  10%|█         | 409M/3.94G [00:05<00:56, 62.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  11%|█         | 419M/3.94G [00:05<00:51, 67.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  11%|█         | 430M/3.94G [00:06<00:54, 64.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  11%|█         | 440M/3.94G [00:06<00:51, 67.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  11%|█▏        | 451M/3.94G [00:06<00:49, 70.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  12%|█▏        | 461M/3.94G [00:06<00:46, 74.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  12%|█▏        | 472M/3.94G [00:06<00:45, 75.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  12%|█▏        | 482M/3.94G [00:06<00:55, 62.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  12%|█▏        | 493M/3.94G [00:06<00:53, 65.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  13%|█▎        | 503M/3.94G [00:07<00:50, 68.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  13%|█▎        | 514M/3.94G [00:07<00:48, 70.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  13%|█▎        | 524M/3.94G [00:07<00:51, 65.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  14%|█▎        | 535M/3.94G [00:07<00:49, 69.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  14%|█▍        | 545M/3.94G [00:07<00:48, 69.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  14%|█▍        | 556M/3.94G [00:07<00:48, 70.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  14%|█▍        | 566M/3.94G [00:07<00:45, 73.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  15%|█▍        | 577M/3.94G [00:08<00:46, 73.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  15%|█▍        | 587M/3.94G [00:08<00:44, 75.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  15%|█▌        | 598M/3.94G [00:08<00:44, 75.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  15%|█▌        | 608M/3.94G [00:08<00:46, 72.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  16%|█▌        | 619M/3.94G [00:08<00:45, 72.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  16%|█▌        | 629M/3.94G [00:08<00:45, 73.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  16%|█▌        | 640M/3.94G [00:08<00:47, 69.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  16%|█▋        | 650M/3.94G [00:09<00:46, 70.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  17%|█▋        | 661M/3.94G [00:09<00:44, 73.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  17%|█▋        | 671M/3.94G [00:09<00:43, 75.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  17%|█▋        | 682M/3.94G [00:09<00:43, 75.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  18%|█▊        | 692M/3.94G [00:09<00:41, 78.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  18%|█▊        | 703M/3.94G [00:09<00:40, 79.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  18%|█▊        | 713M/3.94G [00:09<00:42, 76.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  18%|█▊        | 724M/3.94G [00:10<00:40, 78.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  19%|█▊        | 734M/3.94G [00:10<00:40, 78.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  19%|█▉        | 744M/3.94G [00:10<00:41, 77.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  19%|█▉        | 755M/3.94G [00:10<00:41, 77.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  19%|█▉        | 765M/3.94G [00:10<01:00, 52.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  20%|█▉        | 776M/3.94G [00:10<00:55, 56.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  20%|█▉        | 786M/3.94G [00:11<00:53, 59.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  20%|██        | 797M/3.94G [00:11<00:48, 65.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  20%|██        | 807M/3.94G [00:11<00:45, 69.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  21%|██        | 818M/3.94G [00:11<00:46, 66.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  21%|██        | 828M/3.94G [00:11<00:46, 67.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  21%|██▏       | 839M/3.94G [00:11<00:44, 70.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  22%|██▏       | 849M/3.94G [00:11<00:43, 71.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  22%|██▏       | 860M/3.94G [00:12<00:41, 74.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  22%|██▏       | 870M/3.94G [00:12<00:40, 76.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  22%|██▏       | 881M/3.94G [00:12<00:39, 77.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  23%|██▎       | 891M/3.94G [00:12<00:40, 75.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  23%|██▎       | 902M/3.94G [00:12<00:38, 78.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  23%|██▎       | 912M/3.94G [00:12<00:40, 74.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  23%|██▎       | 923M/3.94G [00:12<00:40, 74.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  24%|██▎       | 933M/3.94G [00:13<00:39, 76.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  24%|██▍       | 944M/3.94G [00:13<00:45, 66.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  24%|██▍       | 954M/3.94G [00:13<00:42, 70.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  24%|██▍       | 965M/3.94G [00:13<00:41, 71.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  25%|██▍       | 975M/3.94G [00:13<00:50, 58.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  25%|██▍       | 986M/3.94G [00:13<00:47, 62.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  25%|██▌       | 996M/3.94G [00:14<00:44, 66.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  26%|██▌       | 1.01G/3.94G [00:14<00:42, 69.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  26%|██▌       | 1.02G/3.94G [00:14<00:40, 72.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  26%|██▌       | 1.03G/3.94G [00:14<00:38, 76.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  26%|██▋       | 1.04G/3.94G [00:14<00:38, 75.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  27%|██▋       | 1.05G/3.94G [00:14<00:44, 65.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  27%|██▋       | 1.06G/3.94G [00:14<00:42, 68.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  27%|██▋       | 1.07G/3.94G [00:15<00:42, 68.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  27%|██▋       | 1.08G/3.94G [00:15<00:39, 72.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  28%|██▊       | 1.09G/3.94G [00:15<00:39, 71.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  28%|██▊       | 1.10G/3.94G [00:15<00:38, 74.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  28%|██▊       | 1.11G/3.94G [00:15<00:36, 77.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  28%|██▊       | 1.12G/3.94G [00:15<00:36, 76.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  29%|██▊       | 1.13G/3.94G [00:15<00:40, 69.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  29%|██▉       | 1.14G/3.94G [00:16<00:40, 69.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  29%|██▉       | 1.15G/3.94G [00:16<00:37, 74.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  30%|██▉       | 1.16G/3.94G [00:16<00:37, 74.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  30%|██▉       | 1.17G/3.94G [00:16<00:37, 74.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  30%|███       | 1.18G/3.94G [00:16<00:36, 75.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  30%|███       | 1.20G/3.94G [00:16<00:37, 72.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  31%|███       | 1.21G/3.94G [00:16<00:39, 69.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  31%|███       | 1.22G/3.94G [00:17<00:37, 72.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  31%|███       | 1.23G/3.94G [00:17<00:40, 66.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  31%|███▏      | 1.24G/3.94G [00:17<00:40, 66.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  32%|███▏      | 1.25G/3.94G [00:17<00:39, 69.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  32%|███▏      | 1.26G/3.94G [00:17<00:38, 70.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  32%|███▏      | 1.27G/3.94G [00:17<00:35, 74.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  32%|███▏      | 1.28G/3.94G [00:17<00:35, 74.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  33%|███▎      | 1.29G/3.94G [00:18<00:35, 75.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  33%|███▎      | 1.30G/3.94G [00:18<00:36, 73.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  33%|███▎      | 1.31G/3.94G [00:18<00:34, 76.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  33%|███▎      | 1.32G/3.94G [00:18<00:33, 77.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  34%|███▍      | 1.33G/3.94G [00:18<00:36, 72.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  34%|███▍      | 1.34G/3.94G [00:18<00:40, 64.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  34%|███▍      | 1.35G/3.94G [00:19<00:46, 56.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  35%|███▍      | 1.36G/3.94G [00:19<00:47, 53.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  35%|███▍      | 1.37G/3.94G [00:19<00:47, 54.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  35%|███▌      | 1.38G/3.94G [00:19<00:48, 52.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  35%|███▌      | 1.39G/3.94G [00:19<00:47, 53.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  36%|███▌      | 1.41G/3.94G [00:20<00:49, 50.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  36%|███▌      | 1.42G/3.94G [00:20<00:50, 49.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  36%|███▌      | 1.43G/3.94G [00:20<00:46, 54.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  36%|███▋      | 1.44G/3.94G [00:20<00:43, 57.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  37%|███▋      | 1.45G/3.94G [00:20<00:41, 59.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  37%|███▋      | 1.46G/3.94G [00:20<00:42, 59.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  37%|███▋      | 1.47G/3.94G [00:21<00:50, 49.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  37%|███▋      | 1.48G/3.94G [00:21<00:47, 52.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  38%|███▊      | 1.49G/3.94G [00:21<00:42, 57.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  38%|███▊      | 1.50G/3.94G [00:21<00:40, 60.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  38%|███▊      | 1.51G/3.94G [00:21<00:46, 52.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  39%|███▊      | 1.52G/3.94G [00:22<00:47, 51.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  39%|███▉      | 1.53G/3.94G [00:22<00:49, 48.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  39%|███▉      | 1.54G/3.94G [00:22<00:48, 50.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  39%|███▉      | 1.55G/3.94G [00:22<00:46, 51.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  40%|███▉      | 1.56G/3.94G [00:23<00:46, 51.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  40%|███▉      | 1.57G/3.94G [00:23<00:51, 46.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  40%|████      | 1.58G/3.94G [00:23<00:50, 46.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  40%|████      | 1.59G/3.94G [00:23<00:49, 47.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  41%|████      | 1.60G/3.94G [00:23<00:45, 51.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  41%|████      | 1.61G/3.94G [00:24<00:45, 51.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  41%|████      | 1.63G/3.94G [00:24<00:44, 51.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  41%|████▏     | 1.64G/3.94G [00:24<00:46, 49.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  42%|████▏     | 1.65G/3.94G [00:24<00:48, 47.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  42%|████▏     | 1.66G/3.94G [00:24<00:44, 51.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  42%|████▏     | 1.67G/3.94G [00:25<00:40, 56.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  43%|████▎     | 1.68G/3.94G [00:25<00:38, 58.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  43%|████▎     | 1.69G/3.94G [00:25<00:35, 63.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  43%|████▎     | 1.70G/3.94G [00:25<00:40, 55.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  43%|████▎     | 1.71G/3.94G [00:25<00:37, 59.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  44%|████▎     | 1.72G/3.94G [00:25<00:37, 58.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  44%|████▍     | 1.73G/3.94G [00:26<00:37, 59.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  44%|████▍     | 1.74G/3.94G [00:26<00:36, 60.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  44%|████▍     | 1.75G/3.94G [00:26<00:40, 54.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  45%|████▍     | 1.76G/3.94G [00:26<00:43, 50.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  45%\u001b[0m\n",
      "\u001b[34m|████▍     | 1.77G/3.94G [00:26<00:41, 52.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  45%|████▌     | 1.78G/3.94G [00:27<00:42, 50.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  45%|████▌     | 1.79G/3.94G [00:27<00:43, 49.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  46%|████▌     | 1.80G/3.94G [00:27<00:41, 52.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  46%|████▌     | 1.81G/3.94G [00:27<00:38, 55.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  46%|████▋     | 1.82G/3.94G [00:27<00:39, 53.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  47%|████▋     | 1.84G/3.94G [00:28<00:39, 53.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  47%|████▋     | 1.85G/3.94G [00:28<00:40, 51.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  47%|████▋     | 1.86G/3.94G [00:28<00:39, 52.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  47%|████▋     | 1.87G/3.94G [00:28<00:39, 52.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  48%|████▊     | 1.88G/3.94G [00:28<00:40, 51.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  48%|████▊     | 1.89G/3.94G [00:29<00:42, 48.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  48%|████▊     | 1.90G/3.94G [00:29<00:39, 52.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  48%|████▊     | 1.91G/3.94G [00:29<00:36, 55.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  49%|████▊     | 1.92G/3.94G [00:29<00:35, 57.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  49%|████▉     | 1.93G/3.94G [00:29<00:38, 52.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  49%|████▉     | 1.94G/3.94G [00:30<00:34, 57.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  49%|████▉     | 1.95G/3.94G [00:30<00:34, 58.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  50%|████▉     | 1.96G/3.94G [00:30<00:33, 58.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  50%|████▉     | 1.97G/3.94G [00:30<00:47, 41.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  51%|█████     | 1.99G/3.94G [00:31<00:30, 64.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  51%|█████     | 2.00G/3.94G [00:31<00:29, 66.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  51%|█████     | 2.01G/3.94G [00:31<00:28, 67.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  51%|█████▏    | 2.02G/3.94G [00:31<00:26, 73.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  52%|█████▏    | 2.03G/3.94G [00:31<00:25, 75.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  52%|█████▏    | 2.04G/3.94G [00:31<00:27, 68.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  52%|█████▏    | 2.06G/3.94G [00:31<00:27, 68.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  52%|█████▏    | 2.07G/3.94G [00:32<00:27, 68.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  53%|█████▎    | 2.08G/3.94G [00:32<00:25, 72.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  53%|█████▎    | 2.09G/3.94G [00:32<00:24, 75.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  53%|█████▎    | 2.10G/3.94G [00:32<00:24, 76.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  53%|█████▎    | 2.11G/3.94G [00:32<00:23, 77.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  54%|█████▎    | 2.12G/3.94G [00:32<00:23, 79.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  54%|█████▍    | 2.13G/3.94G [00:32<00:22, 79.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  54%|█████▍    | 2.14G/3.94G [00:32<00:24, 74.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  54%|█████▍    | 2.15G/3.94G [00:33<00:31, 57.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  55%|█████▍    | 2.16G/3.94G [00:33<00:27, 64.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  55%|█████▌    | 2.18G/3.94G [00:33<00:23, 74.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  56%|█████▌    | 2.19G/3.94G [00:33<00:23, 73.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  56%|█████▌    | 2.20G/3.94G [00:33<00:23, 73.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  56%|█████▌    | 2.21G/3.94G [00:34<00:23, 75.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  56%|█████▋    | 2.22G/3.94G [00:34<00:22, 77.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  57%|█████▋    | 2.23G/3.94G [00:34<00:22, 74.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  57%|█████▋    | 2.24G/3.94G [00:34<00:22, 76.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  57%|█████▋    | 2.25G/3.94G [00:34<00:21, 79.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  57%|█████▋    | 2.26G/3.94G [00:34<00:21, 76.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  58%|█████▊    | 2.28G/3.94G [00:34<00:21, 75.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  58%|█████▊    | 2.29G/3.94G [00:34<00:21, 75.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  58%|█████▊    | 2.30G/3.94G [00:35<00:21, 75.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  58%|█████▊    | 2.31G/3.94G [00:35<00:21, 76.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  59%|█████▊    | 2.32G/3.94G [00:35<00:20, 78.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  59%|█████▉    | 2.33G/3.94G [00:35<00:21, 74.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  59%|█████▉    | 2.34G/3.94G [00:35<00:21, 75.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  60%|█████▉    | 2.35G/3.94G [00:35<00:20, 77.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  60%|█████▉    | 2.36G/3.94G [00:35<00:19, 80.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  60%|██████    | 2.37G/3.94G [00:36<00:20, 78.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  60%|██████    | 2.38G/3.94G [00:36<00:19, 78.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  61%|██████    | 2.39G/3.94G [00:36<00:20, 76.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  61%|██████    | 2.40G/3.94G [00:36<00:20, 76.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  61%|██████    | 2.41G/3.94G [00:36<00:19, 77.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  61%|██████▏   | 2.42G/3.94G [00:36<00:20, 75.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  62%|██████▏   | 2.43G/3.94G [00:36<00:20, 73.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  62%|██████▏   | 2.44G/3.94G [00:37<00:21, 70.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  62%|██████▏   | 2.45G/3.94G [00:37<00:23, 63.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  62%|██████▏   | 2.46G/3.94G [00:37<00:23, 63.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  63%|██████▎   | 2.47G/3.94G [00:37<00:22, 65.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  63%|██████▎   | 2.49G/3.94G [00:37<00:20, 70.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  63%|██████▎   | 2.50G/3.94G [00:37<00:23, 60.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  64%|██████▎   | 2.51G/3.94G [00:38<00:23, 61.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  64%|██████▍   | 2.52G/3.94G [00:38<00:22, 63.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  64%|██████▍   | 2.53G/3.94G [00:38<00:21, 65.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  64%|██████▍   | 2.54G/3.94G [00:38<00:21, 66.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  65%|██████▍   | 2.55G/3.94G [00:38<00:20, 67.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  65%|██████▍   | 2.56G/3.94G [00:38<00:19, 71.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  65%|██████▌   | 2.57G/3.94G [00:38<00:19, 70.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  65%|██████▌   | 2.58G/3.94G [00:39<00:18, 73.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  66%|██████▌   | 2.59G/3.94G [00:39<00:19, 69.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  66%|██████▌   | 2.60G/3.94G [00:39<00:19, 68.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  66%|██████▌   | 2.61G/3.94G [00:39<00:18, 72.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  66%|██████▋   | 2.62G/3.94G [00:39<00:17, 76.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  67%|██████▋   | 2.63G/3.94G [00:39<00:17, 75.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  67%|██████▋   | 2.64G/3.94G [00:39<00:16, 78.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  67%|██████▋   | 2.65G/3.94G [00:40<00:15, 81.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  68%|██████▊   | 2.66G/3.94G [00:40<00:15, 81.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  68%|██████▊   | 2.67G/3.94G [00:40<00:15, 81.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  68%|██████▊   | 2.68G/3.94G [00:40<00:15, 81.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  68%|██████▊   | 2.69G/3.94G [00:40<00:15, 79.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  69%|██████▊   | 2.71G/3.94G [00:40<00:15, 81.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  69%|██████▉   | 2.72G/3.94G [00:40<00:15, 77.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  69%|██████▉   | 2.73G/3.94G [00:40<00:15, 78.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  69%|██████▉   | 2.74G/3.94G [00:41<00:16, 74.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  70%|██████▉   | 2.75G/3.94G [00:41<00:16, 72.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  70%|██████▉   | 2.76G/3.94G [00:41<00:17, 66.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  70%|███████   | 2.77G/3.94G [00:41<00:17, 65.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  70%|███████   | 2.78G/3.94G [00:41<00:17, 66.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  71%|███████   | 2.79G/3.94G [00:41<00:17, 64.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  71%|███████   | 2.80G/3.94G [00:42<00:16, 67.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  71%|███████   | 2.81G/3.94G [00:42<00:16, 69.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  72%|███████▏  | 2.82G/3.94G [00:42<00:15, 71.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  72%|███████▏  | 2.83G/3.94G [00:42<00:16, 69.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  72%|███████▏  | 2.84G/3.94G [00:42<00:16, 66.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  72%|███████▏  | 2.85G/3.94G [00:42<00:15, 69.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  73%|███████▎  | 2.86G/3.94G [00:42<00:15, 71.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  73%|███████▎  | 2.87G/3.94G [00:43<00:14, 74.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  73%|███████▎  | 2.88G/3.94G [00:43<00:14, 75.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  73%|███████▎  | 2.89G/3.94G [00:43<00:13, 77.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  74%|███████▎  | 2.90G/3.94G [00:43<00:13, 77.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  74%|███████▍  | 2.92G/3.94G [00:43<00:13, 78.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  74%|███████▍  | 2.93G/3.94G [00:43<00:13, 76.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  74%|███████▍  | 2.94G/3.94G [00:43<00:14, 69.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  75%|███████▍  | 2.95G/3.94G [00:44<00:14, 68.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  75%|███████▍  | 2.96G/3.94G [00:44<00:13, 73.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  75%|███████▌  | 2.97G/3.94G [00:44<00:12, 76.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  75%|███████▌  | 2.98G/3.94G [00:44<00:12, 76.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  76%|███████▌  | 2.99G/3.94G [00:44<00:12, 77.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  76%|███████▌  | 3.00G/3.94G [00:44<00:12, 76.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  76%|███████▋  | 3.01G/3.94G [00:44<00:12, 76.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  77%|███████▋  | 3.02G/3.94G [00:45<00:12, 73.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  77%|███████▋  | 3.03G/3.94G [00:45<00:13, 69.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  77%|███████▋  | 3.04G/3.94G [00:45<00:12, 71.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  77%|███████▋  | 3.05G/3.94G [00:45<00:11, 76.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  78%|███████▊  | 3.06G/3.94G [00:45<00:11, 77.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  78%|███████▊  | 3.07G/3.94G [00:45<00:10, 79.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  78%|███████▊  | 3.08G/3.94G [00:45<00:10, 79.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  78%|███████▊  | 3.09G/3.94G [00:46<00:11, 74.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  79%|███████▊  | 3.10G/3.94G [00:46<00:10, 77.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  79%|███████▉  | 3.11G/3.94G [00:46<00:10, 81.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  79%|███████▉  | 3.12G/3.94G [00:46<00:09, 82.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  79%|███████▉  | 3.14G/3.94G [00:46<00:09, 82.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  80%|███████▉  | 3.15G/3.94G [00:46<00:10, 74.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  80%|████████  | 3.16G/3.94G [00:46<00:10, 76.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  80%|████████  | 3.17G/3.94G [00:46<00:10, 76.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  81%|████████  | 3.18G/3.94G [00:47<00:10, 75.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  81%|████████  | 3.19G/3.94G [00:47<00:09, 76.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  81%|████████  | 3.20G/3.94G [00:47<00:09, 79.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  81%|████████▏ | 3.21G/3.94G [00:47<00:09, 81.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  82%|████████▏ | 3.22G/3.94G [00:47<00:09, 76.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  82%|████████▏ | 3.23G/3.94G [00:47<00:09, 77.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  82%|████████▏ | 3.24G/3.94G [00:47<00:08, 80.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  82%|████████▏ | 3.25G/3.94G [00:48<00:08, 82.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  83%|████████▎ | 3.26G/3.94G [00:48<00:08, 78.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  83%|████████▎ | 3.27G/3.94G [00:48<00:08, 76.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  83%|████████▎ | 3.28G/3.94G [00:48<00:08, 79.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  83%|████████▎ | 3.29G/3.94G [00:48<00:08, 77.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  84%|████████▎ | 3.30G/3.94G [00:48<00:08, 76.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  84%|████████▍ | 3.31G/3.94G [00:48<00:08, 75.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  84%|████████▍ | 3.32G/3.94G [00:48<00:08, 77.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  85%|████████▍ | 3.33G/3.94G [00:49<00:08, 72.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  85%|████████▍ | 3.34G/3.94G [00:49<00:08, 67.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  85%|████████▌ | 3.36G/3.94G [00:49<00:08, 68.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  85%|████████▌ | 3.37G/3.94G [00:49<00:08, 70.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  86%|████████▌ | 3.38G/3.94G [00:49<00:07, 74.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  86%|████████▌ | 3.39G/3.94G [00:49<00:07, 73.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  86%|████████▌ | 3.40G/3.94G [00:50<00:10, 54.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  87%|████████▋ | 3.43G/3.94G [00:50<00:06, 84.5MB/s]#015Downloadi\u001b[0m\n",
      "\u001b[34mng (…)_pytorch_model.bin\";:  87%|████████▋ | 3.44G/3.94G [00:50<00:06, 79.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  87%|████████▋ | 3.45G/3.94G [00:50<00:06, 76.1MB/s]#015Downloading (…)_pytorch_model.bin\";:  88%|████████▊ | 3.46G/3.94G [00:50<00:06, 77.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  88%|████████▊ | 3.47G/3.94G [00:50<00:06, 76.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  88%|████████▊ | 3.48G/3.94G [00:51<00:05, 78.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  89%|████████▊ | 3.49G/3.94G [00:51<00:06, 72.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  89%|████████▉ | 3.50G/3.94G [00:51<00:05, 76.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  89%|████████▉ | 3.51G/3.94G [00:51<00:05, 77.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  89%|████████▉ | 3.52G/3.94G [00:51<00:05, 80.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  90%|████████▉ | 3.53G/3.94G [00:51<00:05, 80.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  90%|████████▉ | 3.54G/3.94G [00:51<00:05, 78.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  90%|█████████ | 3.55G/3.94G [00:52<00:04, 78.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  90%|█████████ | 3.57G/3.94G [00:52<00:04, 81.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  91%|█████████ | 3.58G/3.94G [00:52<00:04, 83.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  91%|█████████ | 3.59G/3.94G [00:52<00:04, 84.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  91%|█████████ | 3.60G/3.94G [00:52<00:04, 81.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  91%|█████████▏| 3.61G/3.94G [00:52<00:04, 81.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  92%|█████████▏| 3.62G/3.94G [00:52<00:04, 80.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  92%|█████████▏| 3.63G/3.94G [00:52<00:03, 79.2MB/s]#015Downloading (…)_pytorch_model.bin\";:  92%|█████████▏| 3.64G/3.94G [00:53<00:03, 78.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  93%|█████████▎| 3.65G/3.94G [00:53<00:04, 73.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  93%|█████████▎| 3.66G/3.94G [00:53<00:03, 76.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  93%|█████████▎| 3.67G/3.94G [00:53<00:03, 76.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  93%|█████████▎| 3.68G/3.94G [00:53<00:03, 72.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  94%|█████████▎| 3.69G/3.94G [00:53<00:03, 73.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  94%|█████████▍| 3.70G/3.94G [00:53<00:03, 72.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  94%|█████████▍| 3.71G/3.94G [00:54<00:03, 74.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  94%|█████████▍| 3.72G/3.94G [00:54<00:02, 76.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  95%|█████████▍| 3.73G/3.94G [00:54<00:02, 80.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  95%|█████████▍| 3.74G/3.94G [00:54<00:02, 81.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  95%|█████████▌| 3.75G/3.94G [00:54<00:02, 76.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  95%|█████████▌| 3.76G/3.94G [00:54<00:02, 76.5MB/s]#015Downloading (…)_pytorch_model.bin\";:  96%|█████████▌| 3.77G/3.94G [00:54<00:02, 78.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  96%|█████████▌| 3.79G/3.94G [00:55<00:02, 76.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  96%|█████████▌| 3.80G/3.94G [00:55<00:01, 79.4MB/s]#015Downloading (…)_pytorch_model.bin\";:  96%|█████████▋| 3.81G/3.94G [00:55<00:01, 77.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  97%|█████████▋| 3.82G/3.94G [00:55<00:01, 78.8MB/s]#015Downloading (…)_pytorch_model.bin\";:  97%|█████████▋| 3.83G/3.94G [00:55<00:01, 74.6MB/s]#015Downloading (…)_pytorch_model.bin\";:  97%|█████████▋| 3.84G/3.94G [00:55<00:01, 76.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  98%|█████████▊| 3.85G/3.94G [00:55<00:01, 79.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  98%|█████████▊| 3.86G/3.94G [00:56<00:01, 69.7MB/s]#015Downloading (…)_pytorch_model.bin\";:  98%|█████████▊| 3.87G/3.94G [00:56<00:01, 73.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  98%|█████████▊| 3.88G/3.94G [00:56<00:00, 68.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  99%|█████████▊| 3.89G/3.94G [00:56<00:00, 67.9MB/s]#015Downloading (…)_pytorch_model.bin\";:  99%|█████████▉| 3.90G/3.94G [00:56<00:00, 70.0MB/s]#015Downloading (…)_pytorch_model.bin\";:  99%|█████████▉| 3.91G/3.94G [00:56<00:00, 69.3MB/s]#015Downloading (…)_pytorch_model.bin\";:  99%|█████████▉| 3.92G/3.94G [00:56<00:00, 71.8MB/s]#015Downloading (…)_pytorch_model.bin\";: 100%|█████████▉| 3.93G/3.94G [00:57<00:00, 64.5MB/s]#015Downloading (…)_pytorch_model.bin\";: 100%|█████████▉| 3.94G/3.94G [00:57<00:00, 69.2MB/s]#015Downloading (…)_pytorch_model.bin\";: 100%|██████████| 3.94G/3.94G [00:57<00:00, 68.9MB/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:585: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `lightning.pytorch.accelerators.find_usable_cuda_devices` instead.\n",
      "  rank_zero_deprecation(\u001b[0m\n",
      "\u001b[34mGPU available: True (cuda), used: True\u001b[0m\n",
      "\u001b[34mTPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[34mIPU available: False, using: 0 IPUs\u001b[0m\n",
      "\u001b[34mHPU available: False, using: 0 HPUs\u001b[0m\n",
      "\u001b[34m#015Downloading builder script:   0%|          | 0.00/3.93k [00:00<?, ?B/s]#015Downloading builder script: 100%|██████████| 3.93k/3.93k [00:00<00:00, 5.46MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading readme:   0%|          | 0.00/2.38k [00:00<?, ?B/s]#015Downloading readme: 100%|██████████| 2.38k/2.38k [00:00<00:00, 3.45MB/s]\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset teyvat/train to /root/.cache/huggingface/datasets/Fazzie___teyvat/train/0.0.0/62e3cc07a1a94bcb7c0d02f703087023dd935272664b2da5525b893724f24701...\u001b[0m\n",
      "\u001b[34m#015Downloading data:   0%|          | 0.00/467M [00:00<?, ?B/s]#015Downloading data:   2%|▏         | 7.13M/467M [00:00<00:06, 71.3MB/s]#015Downloading data:   3%|▎         | 15.3M/467M [00:00<00:05, 77.7MB/s]#015Downloading data:   5%|▍         | 23.3M/467M [00:00<00:05, 78.3MB/s]#015Downloading data:   7%|▋         | 32.0M/467M [00:00<00:05, 81.8MB/s]#015Downloading data:   9%|▊         | 40.1M/467M [00:00<00:05, 81.0MB/s]#015Downloading data:  10%|█         | 48.5M/467M [00:00<00:05, 81.9MB/s]#015Downloading data:  12%|█▏        | 57.1M/467M [00:00<00:04, 83.3MB/s]#015Downloading data:  14%|█▍        | 65.5M/467M [00:00<00:05, 78.8MB/s]#015Downloading data:  16%|█▌        | 73.9M/467M [00:00<00:04, 80.3MB/s]#015Downloading data:  18%|█▊        | 81.9M/467M [00:01<00:04, 79.5MB/s]#015Downloading data:  19%|█▉        | 89.9M/467M [00:01<00:05, 73.7MB/s]#015Downloading data:  21%|██        | 98.8M/467M [00:01<00:04, 78.1MB/s]#015Downloading data:  23%|██▎       | 107M/467M [00:01<00:04, 80.1MB/s] #015Downloading data:  25%|██▍       | 115M/467M [00:01<00:04, 78.7MB/s]#015Downloading data:  27%|██▋       | 124M/467M [00:01<00:04, 81.6MB/s]#015Downloading data:  28%|██▊       | 133M/467M [00:01<00:04, 82.8MB/s]#015Downloading data:  30%|███       | 141M/467M [00:01<00:04, 75.4MB/s]#015Downloading data:  32%|███▏      | 150M/467M [00:01<00:04, 77.7MB/s]#015Downloading data:  34%|███▎      | 157M/467M [00:01<00:03, 77.5MB/s]#015Downloading data:  35%|███▌      | 165M/467M [00:02<00:03, 77.9MB/s]#015Downloading data:  37%|███▋      | 173M/467M [00:02<00:03, 78.0MB/s]#015Downloading data:  39%|███▉      | 181M/467M [00:02<00:03, 74.3MB/s]#015Downloading data:  40%|████      | 189M/467M [00:02<00:03, 75.0MB/s]#015Downloading data:  42%|████▏     | 196M/467M [00:02<00:04, 67.4MB/s]#015Downloading data:  44%|████▍     | 204M/467M [00:02<00:03, 71.1MB/s]#015Downloading data:  46%|████▌     | 213M/467M [00:02<00:03, 74.7MB/s]#015Downloading data:  47%|████▋     | 221M/467M [00:02<00:03, 77.3MB/s]#015Downloading data:  49%|████▉     | 230M/467M [00:02<00:02, 80.6MB/s]#015Downloading data:  51%|█████     | 239M/467M [00:03<00:02, 83.1MB/s]#015Downloading data:  53%|█████▎    | 248M/467M [00:03<00:02, 85.1MB/s]#015Downloading data:  55%|█████▍    | 257M/467M [00:03<00:02, 79.0MB/s]#015Downloading data:  57%|█████▋    | 266M/467M [00:03<00:02, 82.2MB/s]#015Downloading data:  59%|█████▉    | 275M/467M [00:03<00:02, 84.4MB/s]#015Downloading data:  61%|██████    | 283M/467M [00:03<00:02, 84.7MB/s]#015Downloading data:  62%|██████▏   | 292M/467M [00:03<00:02, 84.0MB/s]#015Downloading data:  64%|██████▍   | 300M/467M [00:03<00:01, 83.9MB/s]#015Downloading data:  66%|██████▌   | 309M/467M [00:03<00:01, 83.4MB/s]#015Downloading data:  68%|██████▊   | 317M/467M [00:03<00:01, 83.1MB/s]#015Downloading data:  70%|██████▉   | 325M/467M [00:04<00:01, 81.1MB/s]#015Downloading data:  71%|███████▏  | 333M/467M [00:04<00:01, 75.7MB/s]#015Downloading data:  73%|███████▎  | 341M/467M [00:04<00:01, 76.4MB/s]#015Downloading data:  75%|███████▍  | 350M/467M [00:04<00:01, 79.1MB/s]#015Downloading data:  77%|███████▋  | 358M/467M [00:04<00:01, 79.7MB/s]#015Downloading data:  79%|███████▊  | 367M/467M [00:04<00:01, 81.6MB/s]#015Downloading data:  80%|████████  | 375M/467M [00:04<00:01, 80.4MB/s]#015Downloading data:  82%|████████▏ | 383M/467M [00:04<00:01, 81.6MB/s]#015Downloading data:  84%|████████▍ | 391M/467M [00:04<00:00, 77.1MB/s]#015Downloading data:  86%|████████▌ | 401M/467M [00:05<00:00, 81.9MB/s]#015Downloading data:  88%|████████▊ | 409M/467M [00:05<00:00, 82.9MB/s]#015Downloading data:  90%|████████▉ | 418M/467M [00:05<00:00, 84.1MB/s]#015Downloading data:  91%|█████████▏| 427M/467M [00:05<00:00, 83.7MB/s]#015Downloading data:  93%|█████████▎| 435M/467M [00:05<00:00, 78.5MB/s]#015Downloading data:  95%|█████████▍| 443M/467M [00:05<00:00, 79.6MB/s]#015Downloading data:  97%|█████████▋| 451M/467M [00:05<00:00, 78.8MB/s]#015Downloading data:  98%|█████████▊| 460M/467M [00:05<00:00, 81.0MB/s]#015Downloading data: 100%|██████████| 467M/467M [00:05<00:00, 79.7MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading data:   0%|          | 0.00/46.1k [00:00<?, ?B/s]#015Downloading data: 100%|██████████| 46.1k/46.1k [00:00<00:00, 780kB/s]\u001b[0m\n",
      "\u001b[34mLoading metadata... /root/.cache/huggingface/datasets/downloads/002cd85d0015cd1a0fca5e8230b953def0a77d6924355e1410881b69a31ea14f\u001b[0m\n",
      "\u001b[34mDataset teyvat downloaded and prepared to /root/.cache/huggingface/datasets/Fazzie___teyvat/train/0.0.0/62e3cc07a1a94bcb7c0d02f703087023dd935272664b2da5525b893724f24701. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m#015Generating train split: 0 examples [00:00, ? examples/s]#015                                                        #015#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 1095.69it/s]\u001b[0m\n",
      "\u001b[34mWARNING:datasets.builder:Found cached dataset teyvat (/root/.cache/huggingface/datasets/Fazzie___teyvat/train/0.0.0/62e3cc07a1a94bcb7c0d02f703087023dd935272664b2da5525b893724f24701)\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 1072.44it/s]\u001b[0m\n",
      "\u001b[34mtrain, Dataset, 234\u001b[0m\n",
      "\u001b[34maccumulate_grad_batches = 1\u001b[0m\n",
      "\u001b[34mSetting learning rate to 8.00e-04 = 1 (accumulate_grad_batches) * 1 (num_gpus) * 8 (batchsize) * 1.00e-04 (base_lr)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/lightning/pytorch/trainer/configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\u001b[0m\n",
      "\u001b[34mWARNING:datasets.builder:Found cached dataset teyvat (/root/.cache/huggingface/datasets/Fazzie___teyvat/train/0.0.0/62e3cc07a1a94bcb7c0d02f703087023dd935272664b2da5525b893724f24701)\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 1067.80it/s]\u001b[0m\n",
      "\u001b[34mMissing logger folder: /opt/ml/df_model/2023-03-02T13-02-27_sd/diff_tb\u001b[0m\n",
      "\u001b[34mWARNING:datasets.builder:Found cached dataset teyvat (/root/.cache/huggingface/datasets/Fazzie___teyvat/train/0.0.0/62e3cc07a1a94bcb7c0d02f703087023dd935272664b2da5525b893724f24701)\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 1112.25it/s]\u001b[0m\n",
      "\u001b[34mDiffusionWrapper has 865.91 M params.\u001b[0m\n",
      "\u001b[34m=========================================================================================\u001b[0m\n",
      "\u001b[34mNo pre-built kernel is found, build and load the cpu_adam kernel during runtime now\u001b[0m\n",
      "\u001b[34m=========================================================================================\u001b[0m\n",
      "\u001b[34mEmitting ninja build file /root/.cache/colossalai/torch_extensions/torch1.12_cu11.3/build.ninja...\u001b[0m\n",
      "\u001b[34mBuilding extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\u001b[0m\n",
      "\u001b[34m[1/2] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/ml/ColossalAI/colossalai/kernel/cuda_native/csrc/includes -I/usr/local/cuda/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.9/site-packages/torch/include/THC -isystem /opt/conda/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -std=c++14 -lcudart -lcublas -g -Wno-reorder -fopenmp -march=native -c /opt/ml/ColossalAI/colossalai/kernel/cuda_native/csrc/cpu_adam.cpp -o cpu_adam.o \u001b[0m\n",
      "\u001b[34m[2/2] c++ cpu_adam.o -shared -L/opt/conda/lib/python3.9/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o cpu_adam.so\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 22.41022038459778 seconds\u001b[0m\n",
      "\u001b[34m=========================================================================================\u001b[0m\n",
      "\u001b[34mNo pre-built kernel is found, build and load the fused_optim kernel during runtime now\u001b[0m\n",
      "\u001b[34m=========================================================================================\u001b[0m\n",
      "\u001b[34mDetected CUDA files, patching ldflags\u001b[0m\n",
      "\u001b[34mEmitting ninja build file /root/.cache/colossalai/torch_extensions/torch1.12_cu11.3/build.ninja...\u001b[0m\n",
      "\u001b[34mBuilding extension module fused_optim...\u001b[0m\n",
      "\u001b[34mAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\u001b[0m\n",
      "\u001b[34m[1/7] c++ -MMD -MF colossal_C_frontend.o.d -DTORCH_EXTENSION_NAME=fused_optim -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/ml/ColossalAI/colossalai/kernel/cuda_native/csrc/kernels/include -I/usr/local/cuda/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.9/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -c /opt/ml/ColossalAI/colossalai/kernel/cuda_native/csrc/colossal_C_frontend.cpp -o colossal_C_frontend.o \u001b[0m\n",
      "\u001b[34m[2/7] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=fused_optim -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/ml/ColossalAI/colossalai/kernel/cuda_native/csrc/kernels/include -I/usr/local/cuda/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.9/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -std=c++14 -c /opt/ml/ColossalAI/colossalai/kernel/cuda_native/csrc/multi_tensor_sgd_kernel.cu -o multi_tensor_sgd_kernel.cuda.o \u001b[0m\n",
      "\u001b[34m[3/7] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=fused_optim -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/ml/ColossalAI/colossalai/kernel/cuda_native/csrc/kernels/include -I/usr/local/cuda/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.9/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -std=c++14 -c /opt/ml/ColossalAI/colossalai/kernel/cuda_native/csrc/multi_tensor_l2norm_kernel.cu -o multi_tensor_l2norm_kernel.cuda.o \u001b[0m\n",
      "\u001b[34m[4/7] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=fused_optim -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/ml/ColossalAI/colossalai/kernel/cuda_native/csrc/kernels/include -I/usr/local/cuda/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.9/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -std=c++14 -c /opt/ml/ColossalAI/colossalai/kernel/cuda_native/csrc/multi_tensor_adam.cu -o multi_tensor_adam.cuda.o \u001b[0m\n",
      "\u001b[34m[5/7] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=fused_optim -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/ml/ColossalAI/colossalai/kernel/cuda_native/csrc/kernels/include -I/usr/local/cuda/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.9/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -std=c++14 -c /opt/ml/ColossalAI/colossalai/kernel/cuda_native/csrc/multi_tensor_lamb.cu -o multi_tensor_lamb.cuda.o \u001b[0m\n",
      "\u001b[34m[6/7] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=fused_optim -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/ml/ColossalAI/colossalai/kernel/cuda_native/csrc/kernels/include -I/usr/local/cuda/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.9/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -lineinfo -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -std=c++14 -c /opt/ml/ColossalAI/colossalai/kernel/cuda_native/csrc/multi_tensor_scale_kernel.cu -o multi_tensor_scale_kernel.cuda.o \u001b[0m\n",
      "\u001b[34m[7/7] c++ colossal_C_frontend.o multi_tensor_sgd_kernel.cuda.o multi_tensor_scale_kernel.cuda.o multi_tensor_adam.cuda.o multi_tensor_l2norm_kernel.cuda.o multi_tensor_lamb.cuda.o -shared -L/opt/conda/lib/python3.9/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o fused_optim.so\u001b[0m\n",
      "\u001b[34mLoading extension module fused_optim...\u001b[0m\n",
      "\u001b[34mTime to load fused_optim op: 56.9327871799469 seconds\u001b[0m\n",
      "\u001b[34msearching chunk configuration is completed in 0.21 s.\u001b[0m\n",
      "\u001b[34mused number: 825.80 MB, wasted number: 6.52 MB\u001b[0m\n",
      "\u001b[34mtotal wasted percentage is 0.78%\u001b[0m\n",
      "\u001b[34mProject config\u001b[0m\n",
      "\u001b[34mmodel:\n",
      "  base_learning_rate: 0.0001\n",
      "  target: ldm.models.diffusion.ddpm.LatentDiffusion\n",
      "  params:\n",
      "    parameterization: v\n",
      "    linear_start: 0.00085\n",
      "    linear_end: 0.012\n",
      "    num_timesteps_cond: 1\n",
      "    ckpt: ./512-base-ema.ckpt\n",
      "    log_every_t: 200\n",
      "    timesteps: 1000\n",
      "    first_stage_key: image\n",
      "    cond_stage_key: txt\n",
      "    image_size: 64\n",
      "    channels: 4\n",
      "    cond_stage_trainable: false\n",
      "    conditioning_key: crossattn\n",
      "    monitor: val/loss_simple_ema\n",
      "    scale_factor: 0.18215\n",
      "    use_ema: false\n",
      "    scheduler_config:\n",
      "      target: ldm.lr_scheduler.LambdaLinearScheduler\n",
      "      params:\n",
      "        warm_up_steps:\n",
      "        - 1\n",
      "        cycle_lengths:\n",
      "        - 10000000000000\n",
      "        f_start:\n",
      "        - 1.0e-06\n",
      "        f_max:\n",
      "        - 0.0001\n",
      "        f_min:\n",
      "        - 1.0e-10\n",
      "    unet_config:\n",
      "      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n",
      "      params:\n",
      "        use_checkpoint: true\n",
      "        use_fp16: true\n",
      "        image_size: 32\n",
      "        in_channels: 4\n",
      "        out_channels: 4\n",
      "        model_channels: 320\n",
      "        attention_resolutions:\n",
      "        - 4\n",
      "        - 2\n",
      "        - 1\n",
      "        num_res_blocks: 2\n",
      "        channel_mult:\n",
      "        - 1\n",
      "        - 2\n",
      "        - 4\n",
      "        - 4\n",
      "        num_head_channels: 64\n",
      "        use_spatial_transformer: true\n",
      "        use_linear_in_transformer: true\n",
      "        transformer_depth: 1\n",
      "        context_dim: 1024\n",
      "        legacy: false\n",
      "    first_stage_config:\n",
      "      target: ldm.models.autoencoder.AutoencoderKL\n",
      "      params:\n",
      "        embed_dim: 4\n",
      "        monitor: val/rec_loss\n",
      "        ddconfig:\n",
      "          double_z: true\n",
      "          z_channels: 4\n",
      "          resolution: 256\n",
      "          in_channels: 3\n",
      "          out_ch: 3\n",
      "          ch: 128\n",
      "          ch_mult:\n",
      "          - 1\n",
      "          - 2\n",
      "          - 4\n",
      "          - 4\n",
      "          num_res_blocks: 2\n",
      "          attn_resolutions: []\n",
      "          dropout: 0.0\n",
      "        lossconfig:\n",
      "          target: torch.nn.Identity\n",
      "    cond_stage_config:\n",
      "      target: ldm.modules.encoders.modules.FrozenOpenCLIPEmbedder\n",
      "      params:\n",
      "        freeze: true\n",
      "        layer: penultimate\n",
      "    use_fp16: true\u001b[0m\n",
      "\u001b[34mdata:\n",
      "  target: main.DataModuleFromConfig\n",
      "  params:\n",
      "    batch_size: 8\n",
      "    num_workers: 0\n",
      "    train:\n",
      "      target: ldm.data.teyvat.hf_dataset\n",
      "      params:\n",
      "        path: Fazzie/Teyvat\n",
      "        image_transforms:\n",
      "        - target: torchvision.transforms.Resize\n",
      "          params:\n",
      "            size: 512\n",
      "        - target: torchvision.transforms.RandomCrop\n",
      "          params:\n",
      "            size: 512\n",
      "        - target: torchvision.transforms.RandomHorizontalFlip\u001b[0m\n",
      "\u001b[34mLightning config\u001b[0m\n",
      "\u001b[34mtrainer:\n",
      "  accelerator: gpu\n",
      "  devices: 1\n",
      "  log_gpu_memory: all\n",
      "  max_epochs: 1\n",
      "  precision: 16\n",
      "  auto_select_gpus: false\n",
      "  strategy:\n",
      "    target: strategies.ColossalAIStrategy\n",
      "    params:\n",
      "      use_chunk: true\n",
      "      enable_distributed_storage: true\n",
      "      placement_policy: cuda\n",
      "      force_outputs_fp32: true\n",
      "      min_chunk_size: 64\n",
      "  log_every_n_steps: 2\n",
      "  logger: true\n",
      "  default_root_dir: /tmp/diff_log/\u001b[0m\n",
      "\u001b[34mlogger_config:\n",
      "  wandb:\n",
      "    target: loggers.WandbLogger\n",
      "    params:\n",
      "      name: nowname\n",
      "      save_dir: /tmp/diff_log/\n",
      "      offline: opt.debug\n",
      "      id: nowname\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/lightning/pytorch/loggers/tensorboard.py:188: UserWarning: Could not log computational graph to TensorBoard: The `model.example_input_array` attribute is not set or `input_array` was not given.\n",
      "  rank_zero_warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/lightning/pytorch/utilities/data.py:84: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 8. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\u001b[0m\n",
      "\u001b[34m#015Training: 0it [00:00, ?it/s]#015Training:   0%|          | 0/30 [00:00<?, ?it/s]#015Epoch 0:   0%|          | 0/30 [00:00<?, ?it/s] [03/02/23 13:06:06] INFO     colossalai - colossalai - INFO:                    \n",
      "                             /opt/ml/ColossalAI/colossalai/nn/optimizer/zero_opt\n",
      "                             imizer.py:217 step                                 \n",
      "                    INFO     colossalai - colossalai - INFO: Found overflow.    \n",
      "                             Skip step                                          \u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\u001b[0m\n",
      "\u001b[34m#015Epoch 0:   3%|▎         | 1/30 [00:06<03:16,  6.78s/it]#015Epoch 0:   3%|▎         | 1/30 [00:06<03:16,  6.79s/it, loss=1.03, v_num=0, train/loss_simple_step=1.030, train/loss_vlb_step=1.030, train/loss_step=1.030, global_step=0.000, lr_abs=8e-10][03/02/23 13:06:07] INFO     colossalai - colossalai - INFO:                    \n",
      "                             /opt/ml/ColossalAI/colossalai/nn/optimizer/zero_opt\n",
      "                             imizer.py:217 step                                 \n",
      "                    INFO     colossalai - colossalai - INFO: Found overflow.    \n",
      "                             Skip step                                          \u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/lightning/pytorch/utilities/data.py:84: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('train/loss_simple', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "  warning_cache.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('train/loss_vlb', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "  warning_cache.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('train/loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "  warning_cache.warn(\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "from sagemaker.estimator import Estimator\n",
    "instance_type = 'ml.g5.2xlarge'\n",
    "estimator = Estimator(role=role,\n",
    "                      instance_count=1,\n",
    "                      instance_type=instance_type,\n",
    "                      volume_size=50,\n",
    "                      image_uri='310850127430.dkr.ecr.us-west-2.amazonaws.com/diffusion')\n",
    "\n",
    "estimator.fit('s3://sagemaker-us-west-2-310850127430/2023-02-26T12-59-14_sd/configs/2023-02-26T12-59-14-lightning.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20adfaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
